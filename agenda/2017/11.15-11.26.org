* 今日计划
** TODO integrate with editor

refactor config:
rename?



pass main

pass "draw box"

unit test




** TODO add dispose logic
use lazy dispose???
////(so that no need to addDisposeHandle!!!)
remove "isAlive" logic?
memoryUtils=>transform optimize:
reallocate 0-( firstIndex - 1 ), reset transformData.index!




gpu optimize:
memory pool:
texture 
buffer

(define pool in render setting)





** TODO implement batch
support batch dispose







** TODO implement clone


** TODO implement "restore from state"




////**** TODO add hasChild,removeChild logic



** TODO rollup: generate index.re



////**** TODO implement "clone"




rollup-plugin-bucklescript: https://www.npmjs.com/package/rollup-plugin-bucklescript








** TODO publish
increase test coverage to 95%



change README.org:
a functional, high performance webgl 3d engine
















* 完成事项
** DONE integrate with editor
CLOSED: [2017-11-16 Thu 18:38]

refactor config:
rename?



//pass main

//pass "draw box"

unit test:
//pass app_test

////resize canvas

////unit test

//adaptor add more

//refactor


** DONE add dispose logic
CLOSED: [2017-11-23 Thu 10:42]
use lazy dispose???
////(so that no need to addDisposeHandle!!!)
remove "isAlive" logic?
memoryUtils=>transform optimize:
reallocate 0-( firstIndex - 1 ), reset transformData.index!

//add isAlive

//test transform



//dispose gameObject:
//need reallocate? yes!

//test



//test: 
test init gameObject




//pass benchmark test!



benchmark test:
only test dispose gameObject and its transform


//fix: 
fix benchmark test bug: create 2000 boxes, dispose 1000 , bug!!!
test render
////test get buffer->getVertices/getIndices




////finish indexOf optimize:
pass unit test
pass render test





//todo check shouldn't dispose geometry before init






optimize:
//clean gameobject->componentMap
//clean meshRenderer,transform->disposeIndexArray
////reallocate material,transform,meshRenderer,cameraController? or not (limit max count < 10000?)
////meshRenderer: add render gameObject map!

cache finded shaderLibDataArray!


////geomemtry-> configMap, disposeUidMap?indexMap? 


////job should only get once

//solve memory leak!







dispose geometry:
//gpu optimize:
memory pool:
texture 
buffer

(define pool in render setting)



//test:
use pool:
add buffer  to pool after dispose
not create new buffer

bind pooled element array buffer before draw







//pass unit:
//feat: add reallocate geometry logic
//feat: add geometry->indexMap to map index to allocated new index!
//reallocate gameObject->meshRenderer,... map
//test ComponentSystem->generateIndex
//GameObject_test: test dispose geometry,... component
//test reallocate geometry:
data.indicesCountCacheMap = newIndicesCountCacheMap;
data.verticesCountCacheMap = newVerticesCountCacheMap;

//test "optimize: ShaderSystem->_init->addAttributeSendData,addUniformSendData, addDrawPointsFunc: if shader index exist,
not add"

//fix: buffer,indicesCount,verticesCount should be out(per for geometryIndex)!





//optimize geometry->indexMap: reduce call count of get mapped index
(not get mapped index in geometry system/utils)




//fix:
todo check shouldn't dispose xxx before init

////decrease geometryPointDataBufferCount?(source is too large)




//fix:
////component not check isAlive(add test cases: can't check!)
component check isAlive(add test cases: check!)(geometry should check)
gameObject still check isAlive


finish todo:
//check isAlive





refactor:
//remove geometryDataBufferCount
////ensure->should exist: can use Obj.magic and judge undefine!???
//rename box.html to benchmark_basic_boxes.html

//test->getGl move to tool
//rename IndexBuffer to ElementArrayBuffer
////rename GLSL to Glsl






refactor: 
//rename TransformXXXUtils to transformXXXUtils
//rename UId to Uid
////rename bufferConfig: rename meshRendererDataBufferCount to meshRendererCount
//clean code




//finish todo





//finish other components

** DONE batch dispose
CLOSED: [2017-11-23 Thu 18:48]
//support batch dispose:
need optimize meshrenderer->dispose->remove gameObject from renderGameObjectArray

optimize:
dispose->meshRenderer->renderGameArray



** DONE implement clone
CLOSED: [2017-11-26 Sun 16:52]
batch clone

//can reuse:
material's shaderLib/shaderIndex
geometry's vertices/indices
...

//pass compile

//commit:
geometry: distinguish index and mappedIndex


//pass unit test


add material:
////shader optimize




//pass unit test




//optimize memory:
isClonedMap
buffer map


//fix geometry:
gameObjectMap?(use mappedIndex?)


//refactor:
rename geometry->configData to computeConfigData
remove Geometry.re->getXXXConfigData



//pass benchmark test:
//fill type arr with type arr:
//use set instead of for?(geometry->setVertices/setIndices, reallocate geometry)
(computeFunc return arr instead of typeArr; when clone geometry, make typeArr from source geometery's arr!!!???)




//optimize clone material:
shader optimize



//optimize:
hashmap whose key in number should not int:
use sparse array map instead!(array with int key)


//add cameraController


//pass unit test




////test:
test BoxGeometry->setConfigData, getConfigData after reallocate geometry
//reallocate geometry: test isClonedMap




////compare:
update or 






refactor:
//rename MainSystem->configStateXXX to configXXX
//clean code



//finish todo


//refactor:
package.json: 
remove:
    "jest": "^21.2.1",
    "jest-cli": "^21.2.1",


upgrade to 0.2.1:
    "wonder-bs-jest": "0.2.0",






//fix glsl-compiler: 
not ignore lib/src, ignore lib/test
update wonder.js->package.json





** DONE publish
CLOSED: [2017-11-26 Sun 18:00]


increase test coverage to 95%


give performance report

//change README.org:
a functional, high performance webgl 3d engine






* 编辑器计划

//how to export ui code for contribute?

//resize canvas and viewport 

** TODO add "set basic material color of current gameObject" after finish scene tree
//merge color branch


//add "getMaterial" in GameObjectAdaptor.ts


solve run test=>colorUtils bug:
wait arvin push, then fetch and try
after solve, push



* 中期研究

* 明日计划
*** TODO implement "restore from state"




*** TODO support render worker

use module functors?


conditional compile:
https://github.com/facebook/reason/issues/1359
use bsb-native?


file names end with "ReWo" instead of "Utils"?


*** TODO publish






* TODO 未来7日计划
*** TODO support webgl2





*** TODO publish





*** TODO add light,texture




**** TODO optimize
webgl1->v/pMatrix should has cache, while mMatrix should not has!

gpu optimize:
memory pool:
texture 




*** TODO publish




*** TODO add load asset(v)




**** DONE learn
CLOSED: [2017-09-17 Sun 15:51]
Game Engine Gems 1=> chapter 2 The Game Asset Pipeline

***** DONE optimize resource management
CLOSED: [2017-09-17 Sun 15:51]
https://developer.nvidia.com/gpugems/GPUGems2/gpugems2_chapter05.html
https://developer.nvidia.com/gpugems/GPUGems2/gpugems2_chapter33.html
https://www.gamedev.net/forums/topic/449794-opengl-multi-streaming-with-vbos/
Game Engine Gems 1=> chapter 11 A GPU-Managed Memory Pool
https://developer.nvidia.com/gpugems/GPUGems2/gpugems2_chapter29.html
**** DONE study
CLOSED: [2017-09-18 Mon 11:02]
Cooperative Scheduling of Background Tasks API:
implement library
use it to load

use fetch


streams api?


////3d tiles?


learn es6


**** DONE load image
CLOSED: [2017-09-21 Thu 19:43]

load
read//set?

//preload?



//test load image when loopBody

//TextureAsset add "toTexture"

//unit test

fix worker


//checkout to editor:
fix .gitignore: dist



////fix wonder-frp bug

//unit test:
test: not init map manager when init, init new need textures when draw!
test: TextureWorkerData.index
test: TextureWorkerData.sourceMap(update?)
pass other tests!


//test webgl1


//refactor:
sendDrawData



//support change map at runtime:
basic
light


//unit test


refactor:
////rename addMap to setMap
rename SpecifyXXX to SpecificXXX(and handle lower cases!)




////implement streamLoad


//test set image when loopBody

//unit test


//refactor:
clean todo

**** DONE refactor
CLOSED: [2017-09-22 Fri 12:06]
//use task API


//wonder-frp:
solve duplicate files bug!
Operator.ts=>import cause?


//move task to new project



**** TODO load sceneGraph .wd

refactor:
////upper case:
material_config
shaderLib_generator


***** TODO implement batch
support batch create:
batch add components


test batch benchmark in benchmark test:
use bs-benchmark.js?

https://segmentfault.com/a/1190000003486676
https://johnresig.com/blog/javascript-benchmark-quality/
https://calendar.perfplanet.com/2010/bulletproof-javascript-benchmarks/


add batch functions:
pass transform
batch update texture
batch set geometry data
...


finish tranform


pass unit test



test batch benchmark in unit test:
to decide use which createBatch?


***** TODO upgrade .wd to gltf2.0
////support .wdglb

not support glb


TEXCOORD_0, TEXCOORD_1, COLOR_0. 
Client implementations must support at least two UV texture coordinate sets ////, one vertex color, and one joints/weights set.  

now not support COLOR


new geometry:
TANGENT(not support yet)


Images
a reference to a bufferView; in that case mimeType must be defined.

{
    "images": [
        {
            "uri": "duckCM.png"
        },
        {
            "bufferView": 14,
            "mimeType": "image/png" 
        }
    ]
}


////not support image bufferView


////use fetch to refactor load image








finish more component:
geometry,
camera,
light,
material,
tag?





***** TODO use fp refactor loader, AssetDatabase


***** TODO converter:
support convert .obj, .fbx, .gltf to .wd v2.0

use .gltf 2.0 model to test wd 2.0!




////use stream api to load model:
https://github.com/AVGP/streaming-webgl-demo

***** TODO do
http://bitsquid.blogspot.ch/2014/10/building-data-oriented-entity-system_10.html



**** TODO add AssetDatabase to support aync load asset
move out to be a project in wonder group for wonder-editor use!


**** TODO support hot loading
https://blog.molecular-matters.com/2012/01/31/a-content-pipeline-for-fast-iteration-times/
https://www.youtube.com/watch?v=BQPpZkRk6y4



*** TODO write editor demo: edit and run(hot loading)

**** TODO replace wonder-frp with most.js
should test benchmark!
(test from array(sync) and from event(async)!)


refer to:
https://github.com/cujojs/most/tree/master/test/perf
https://survivejs.com/blog/most-interview/



***** TODO editor use redux-most?
https://github.com/joshburgess/redux-most



**** TODO give loading asset performance report



*** TODO publish




*** TODO add event and picker

*** TODO publish



*** TODO improve debug and test
**** TODO debug panel
profile can be defined in render config json!



compute:
fps

render time:
cpu time
gpu time



memory:
cpu memory:
total
typeArray
...


gpu memory:
total
textures
vertex buffers
index buffers
GBuffer


frame counters:
vertices count
triangles count



show these if setMainConfig=>showDebugPanel:true




**** TODO add benchmark test

http://taobaofed.org/blog/2016/01/13/measuring-fps/
http://wicg.github.io/frame-timing/
https://segmentfault.com/a/1190000011516068




https://github.com/zploskey/bs-puppeteer
https://github.com/GoogleChrome/puppeteer

**** TODO add render test


**** TODO publish


*** TODO add tag

*** TODO publish















** TODO summary


** TODO pass in window
*** TODO chrome

*** TODO firefox

*** TODO ie11




** TODO add event
*** TODO move event manager to be npm package
*** TODO add dom event
**** TODO add ray picking


** TODO camera
ortho camera

arcball camera controller
fly camera controller



** TODO add render test
*** TODO enhance render test

ci can run render test

can generate correct image in the debug page of render


use headless-gl + jest + ci to test!!!???
https://github.com/socialtables/webgl-test-ci



**** TODO solve "render test not pass in outer screen" problem

**** TODO move render test to npm/submodule
move more samples there


add README.org:
todo: add compare in two way:
- overlap yours and correct img
- get diff pixel img

**** TODO add render test

*** TODO add benchmark auto test
use benchmarkjs:
https://github.com/glennsl/bs-benchmarkjs


build basic test scenes

compare with time



** TODO extend
*** TODO finish the way which user can extend by npm/github repo
need use other instead of npm?
(learn http://bitsquid.blogspot.it/2016/01/introducing-stingray-package-manager-spm.html)

*** TODO add script



*** TODO add custom material+custom shader
*** TODO user can write own .glsl can register to npm
modify render config(shader config json?), support build npm->glsl to ShaderChunk.ts?



** TODO Voxel
*** TODO voxel terrain
marching cube
destruct, dig hole
lod
multi materials(multi layer)

voxel billboard?(for tree, grass)

triplanar mapping




*** TODO voxel model(which can be destruct)(static?)
marching cube

**** TODO generate a new uv map of a new polygon model generated by a voxel model(marching cube?) which can map the same texture of the origin polyon model's
voxel farm:

http://procworld.blogspot.com/2016/05/applying-textures-to-voxels.html
***** We had to write voxelization routines that captured the UV data with no ambiguities.



***** we had to make sure our dual contouring methods could output the UV data back into triangle form.

The realtime compression had to be now aware of the UV space, and remain fast enough for realtime use.
And last but not least we knew voxel content would be edited and modified in many sorts of cruel ways. We had to understand how the UV data would survive (or not) all these
transformations. 

***** internal voxels do not have UV info, but a regular material that is exposed when the surface voxels are gone.
***** Only the surface voxels have UVs.






Rethinking Texture Mapping:
http://www.cemyuksel.com/courses/conferences/siggraph2017-rethinking_texture_mapping/rethinking_texture_mapping_course_notes.pdf



volume-encoded-uv-maps
http://vcg.isti.cnr.it/volume-encoded-uv-maps/volume-encoded-uv-maps.pdf
http://vcg.isti.cnr.it/volume-encoded-uv-maps/volume-encoded-uv-maps_additional.pdf
http://vcg.isti.cnr.it/volume-encoded-uv-maps/



tileTrees
https://www-sop.inria.fr/reves/Basilic/2007/LD07/LD07.pdf
https://www-sop.inria.fr/reves/Basilic/2008/DL08/



octree texture
http://www.antexel.com/sylefeb/octreetex/
http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/DeBry02.pdf
http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Benson02.pdf



Examining Automatic Texture Mapping of Arbitrary Terrains: https://www.diva-portal.org/smash/get/diva2:422722/FULLTEXT01.pdf


should learn from book:
《TEXTURING And MODELING A Procedural Approach》


polycube map:
http://vcg.isti.cnr.it/polycubemaps/


Perfect Spatial Hashing:
http://hhoppe.com/perfecthash.pdf
https://github.com/Jinxit/psh




need study:
Unified Texture Management for Arbitrary Meshes: http://evasion.inrialpes.fr/Publications/2004/LDN04/RR-5210.pdf






***** TODO references
https://emnh.github.io/rts-blog/2017/04/25/10_voxelization.html
Examining Automatic Texture Mapping of Arbitrary Terrains: https://www.diva-portal.org/smash/get/diva2:422722/FULLTEXT01.pdf


**** TODO construct examples in game
In Infinity: Battlescape, we designed our space stations, bases and factories to be modular. This means that we model &
texture independant modules, which can get attached together in various configuration layouts. Here's one of such
layouts for a space station: https://www.gamedev.net/blogs/entry/2262351-patch-0160-screenshots/

https://www.youtube.com/watch?v=DQg6mpjQMRo&feature=youtu.be









** TODO blog
完成博文：展示函数式编程（fp)＋面向数据(do)＋组件架构在引擎中的设计，为编辑器架构设计提供参考

** TODO defer+forward render
**** TODO support transparent

support use forward shading to draw transparent objects



** TODO study how to texture by using tool
https://www.youtube.com/watch?v=p4ngVoGIj1Q
https://www.youtube.com/watch?v=LcCQKuWPhXk
https://www.youtube.com/watch?v=u2GAHnDaUpU



uv map:
https://www.youtube.com/watch?v=f2-FfB9kRmE
https://www.youtube.com/watch?v=W-ZmDKuB6HI



texture painting:
https://www.youtube.com/watch?v=Hr_itixx0Yo




** TODO refactor: add defer render pipeline
refer to stingray=>renderer


user can expand pipeline:
render Object?

add render component?:
defer shading render component
forward render component


refactor glsl:
separate defer render, front render, webgl1, webgl2


need user render script?



*** TODO unit test


*** TODO pass render worker



*** TODO unit test




** TODO publish

** TODO run in mobile
*** TODO add mobile render pipeline

////** TODO publish alpha.6





** TODO use glsl-optimizer
optimize:
wonder-glsl-compiler should read shader_libs.re and generate completely vs,fs source(buildGLSLSouce)



use it to generate optimized glsl code when gl.shaderSource:
http://aras-p.info/blog/2010/09/29/glsl-optimizer/
https://github.com/aras-p/glsl-optimizer





** TODO refactor: data driven renderer

** TODO publish alpha.8



** TODO add pbr?
http://bitsquid.blogspot.com/2017/07/validating-materials-and-lights-in.html

https://cesium.com/blog/2017/08/08/physically-based-rendering-in-cesium/
https://github.com/KhronosGroup/glTF-WebGL-PBR

** TODO publish


** TODO shadow
use esm instead of vsm?
http://www.klayge.org/2013/10/07/%E5%88%87%E6%8D%A2%E5%88%B0esm/




*** TODO support forward shading shadow

*** TODO support defer shading shadow
优化4：Shadowing pass
KlayGE用shadow map渲染阴影。其生成shadow map的过程和普通方法一样，这里就不累赘了。在使用shadow map的时候有两个选择，以前
的方法是在lighting pass里计算光照的时候就查询shadow map，同时计算阴影。另一个方法来自Screen space shadow map。在每个
lighting pass之前加一个shadowing pass，仅仅查询shadow map和计算阴影本身（结果是个灰度图）。这样的好处是，shadowing可以在
更低的分辨率上计算，而不用和lighting pass用同样的分辨率，提高效率。另外，shadowing pass的结果可以像screen space shadow
map那样做一次blur，在让lighting pass使用。 


https://newq.net/publications/more/s2015-many-lights-course => Part 3: Efficient Shadows from Many Lights



*** TODO pass render worker


** TODO optimize: improve data oriented
http://bitsquid.blogspot.com/2017/05/rebuilding-entity-index.html
https://www.youtube.com/watch?v=PmEeW9hjqrM&


** TODO finish Transform(rotation, translate...)
implement all functions

add more unit


** TODO Wonder.js/wonder-package not post install global packages!
"postinstall": "sudo npm install -g typescript@next && sudo npm install -g rollup && sudo npm install -g typescript-formatter",



** TODO refactor
change Director,GPUDetector to function!

** TODO demo test(in new branch to test)(no unit test,render test)
*** TODO Data driven renderer
rewrite renderer
*** TODO try use webAssembly in engine for cpu compute
**** TODO write a webAssembly demo
use https://github.com/01alchemist/TurboScript to compile js to webAssembly
use webAssembly js api to invoke it in js in demo
*** TODO render rewrite(v)
**** TODO transient Resource System
https://www.slideshare.net/DICEStudio/framegraph-extensible-rendering-architecture-in-frostbite
memory pool for textures



*** TODO refactor
refactor getComponent=>paradigms



add "compilerOptions" to tsconfig.json(add to base tsconfig.json, others extend it)


mateiral add to meshrenderer


use es5,es6=>Object added method to refactor:
use assign instead of extend?

optimize deep clone:
http://stackoverflow.com/questions/122102/what-is-the-most-efficient-way-to-deep-clone-an-object-in-javascript?rq=1
http://stackoverflow.com/questions/728360/how-do-i-correctly-clone-a-javascript-object?rq=1

use keys in Hash=>getKeys?


upgrade typescript to 2.2

*** TODO loader,asset data driven

refer to https://blog.molecular-matters.com/2013/05/17/adventures-in-data-oriented-design-part-3b-internal-references/:
 you can still make sure that the scripts themselves are contiguous in memory by allocating them with a suitable
 allocator. As an example, I use a linear/stack-based allocator for all resources being loaded, and resources are sorted
 inside their resource bundles. This means that in memory, all script code (also meshes, textures, etc.) will be right
 next to each other, with pointers to scripts stored elsewhere. 




use string id:
http://cowboyprogramming.com/2007/01/04/practical-hash-ids/
http://www.randygaul.net/2015/12/11/preprocessed-strings-for-asset-ids/



** TODO advanced asset load
*** TODO support stream load
Scene streaming management:
Easily create vast worlds by streaming objects in and out of your scenes. Divide your world into subscenes to avoid
editing conflicts. 

https://stackoverflow.com/questions/25823729/large-3d-scene-streaming
https://forum.unity.com/threads/released-sectr-stream-seamless-scene-streaming.229907/

** TODO continue rewrite(keep engine size min)(1.0.0-alpha.xxx)
*** TODO use Data-Driven Design?





Applications in Games
• Particles, Soft-body, Rigid-body, Fluid Simulation
• Collision, Visibility Detection
• Skeletal Animation
• Group Behavior Simulation

http://twvideo01.ubm-us.net/o1/vault/gdcchina14/presentations/833779_MiloYip_ADataOriented_EN.pdf

http://www.slideshare.net/DICEStudio/culling-the-battlefield-data-oriented-design-in-practice



Think about data first, and code second. Class hierarchies aren’t important, but data access patterns are.
Think about how data in your game is accessed, how it is transformed, and what you end up doing with it, e.g. particles, skinned characters, rigid bodies, and tons of other examples.
When there’s one, there’s many. Think in streams of data.
Be aware of the overhead of virtual functions, pointers to functions, and pointers to member functions.



study "virtual function"




**** TODO unity
https://forum.unity3d.com/threads/data-oriented-designed-game-in-unity.350118/

what's Unity DOES?
Unity DOES use DOD, in the places where it eeks out large benefits.

Mesh data and texture data just makes more sense that way. 
*** TODO support multi-thread(maybe need rewrite runtime)
js multi thread:
https://blog.mozilla.org/javascript/2015/02/26/the-path-to-parallel-javascript/
https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer

simd
https://blog.mozilla.org/javascript/2015/03/10/state-of-simd-js-performance-in-firefox/

extract multi thread object/component?


**** TODO multi-thread render
http://www.cnblogs.com/ixnehc/archive/2008/09/04/1284708.html
http://www.bennychen.cn/2011/01/%E5%85%B3%E4%BA%8E%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E6%95%B4%E7%90%86%E5%92%8C%E6%80%9D%E8%80%83/
http://www.cppblog.com/flagship/archive/2009/03/25/77886.html

unity:
https://blogs.unity3d.com/cn/2015/02/06/extending-unity-5-rendering-pipeline-command-buffers/
https://docs.google.com/document/d/1e2jkr_-v5iaZRuHdnMrSv978LuJKYZhsIYnrDkNAuvQ/edit
https://github.com/Unity-Technologies/ScriptableRenderLoop
**** TODO multi-thread load asset



support load multi part of one model?
(refer to http://www.inka3d.com/)
**** TODO multi-thread collision(refer to babylonjs=>worker)
*** TODO rewrite render loop(refer to unity)
**** TODO refactor?
refactor: move material to renderer?


add billboard/line renderer?

add skin mesh renderer?
https://docs.unity3d.com/Manual/class-SkinnedMeshRenderer.html

**** TODO support command buffer
https://docs.unity3d.com/Manual/GraphicsCommandBuffers.html
https://docs.unity3d.com/ScriptReference/Rendering.CommandBuffer.html


add more render command(e.g., set render target, ...)

**** TODO support Scriptable Render Loops
https://docs.google.com/document/d/1e2jkr_-v5iaZRuHdnMrSv978LuJKYZhsIYnrDkNAuvQ/edit#
https://github.com/Unity-Technologies/ScriptableRenderLoop

TL;DR
Motivation
Need to perform better on modern hardware
Easier to customize & extend, less “black box”
Easier dealing with backwards compatibility
Scriptable Render Loops: the new foundation
API Overview
Usage, inner workings, performance
New built-in “HD Render Loop”
Lighting Features
Material Features
Camera Features
Workflow / Debug Features
Appendix - Current Rendering Pipeline in Unity
Shadows
Forward Rendering
Deferred Shading
Customization
TL;DR
Reimagine the rendering pipeline to support more flexibility and transparency. The main Unity rendering pipeline will be replaced by multiple "Render Loops", built in C# on a C++ foundation. The C# code for the "Render Loops" will be open-sourced on GitHub, enabling users to investigate, enhance, or create their own custom render loops.
Motivation
Current Unity’s rendering pipeline is described in Appendix - Current Rendering Pipeline. There are several improvements we want to make -- the major ones are spelled below.
Need to perform better on modern hardware
Both “one light per draw call” forward rendering, and “stencil mark + draw shape per light” deferred shading are not exactly modern approaches -- they were fine for roughly DX9 hardware, but with advent of compute shaders generally we can do much better. Our forward shading suffers from too many draw calls (CPU + vertex transform cost) and bandwidth consumed by repeated sampling of surface textures & blending; whereas deferred shading suffers from draw call count, not enough light culling, cost of doing stencil mark + draw call per light and repeated fetching of G-buffer data. Additionally, on tile-based GPUs it does tile store+load too much when realtime shadows are involved, and does not take advantage of tile storage or framebuffer fetch.
We’d like to ship Unity with an out-of-the box rendering pipeline that is targeted at modern hardware -- where we can rely on API & GPU features like compute shaders, draw call instancing, constant buffers etc.
Easier to customize & extend, less “black box”
Most of Unity users would probably not modify the built-in rendering pipeline, but some of the more advanced teams do want to modify or extend it. So it has to be extensible and much less opaque than today.
While the current rendering pipeline is somewhat extensible (users can write their own shaders, manually control camera rendering, change settings, extend the rendering pipeline with command buffers), it is not extensible enough. Additionally, it is too much of a “black box”, and while the documentation, conference presentations, MIT-licensed built-in shader source code and community knowledge does fill in the gaps, some parts are hard to understand without a Unity source code license. We want all the high level code and shader/compute code to be a MIT-licensed open source project, similar to how Post-Processing, UI or Networking already are.
A “single render pipeline for everything” likely has some compromises that make it more flexible at expense of performance. We imagine that, for example, these kinds of rendering pipelines would make sense in many cases:
Optimized for modern PC/console (DX11 baseline, “high end” graphics).
Optimized for on-tile storage of mobile GPUs, using framebuffer fetch or other available techniques.
Optimized for VR (e.g. forward shading + MSAA, single-pass rendering, caching/sharing eye rendering results in distance, various schemes of viewport/resolution stitching).
Optimized for low-end devices (old mobile, old PC) or simple 2D games: simple one pass lighting (limited # of lights, and/or vertex lighting).
These don’t have to be physically separate rendering pipelines, could be options in some other existing pipelines.
Easier dealing with backwards compatibility
This is a hard problem for us at Unity R&D, basically doing big changes to how the rendering engine works is quite hard -- mostly because people do expect to update to a more recent Unity version and have things “still working as they did”. Except when they don’t, i.e. they actively want new changes... For example, we changed Standard shader from Blinn-Phong to GGX specular in Unity 5.3 -- mostly this is a good thing, except for people who were mid-production and now their specular behaves differently (so they probably have to re-tweak their lighting setups and materials).
We’re thinking, that if the high level structure of the rendering code, and all the shader code, was easily “forkable” and versionable, then this problem could become easier.

Scriptable Render Loops: the new foundation
We think all or most of the problems listed above can be solved fairly elegantly by having a solid, orthogonal, performant foundation to build upon, which would basically be “an ability to render sets of objects with various filtering criteria efficiently”. The division of work would be:
Unity C++ code
C#/shader code (MIT open source)
Culling
Render set of objects with filter/sort/params
Internal graphics platform abstraction
Camera setup
Light setup
Shadows setup
Frame render pass structure & logic
Shader/compute code

The C++ side would be mostly not even aware that things like “Camera” or “Light” exist; e.g. culling code gets arrays of bounding primitives and matrices / culling planes as input. It does not care whether it’s culling main view, reflection rendering view or a shadow map view.
Likewise, rendering code is expressed in terms of “from the culling results, render everything that is within opaque render queues range, has this shader pass and does not have that shader pass, sort by material then by distance, setup light probe constants per-object”. There is some amount of conventions and built-in things in there, mostly in what kind of data should be set as per-instance data for each object (light probes, reflection probes, lightmaps, per-object light lists etc.).
There’s a lot of underlying platform graphics abstraction changes that we’re doing in order to be able to provide a robust, high performance and orthogonal set of “building blocks” to build scriptable render loops upon, but they are mostly outside of the scope of this document. Some of the changes worked on are:
Expose “Buffer” as a C# class, that would be used for all kinds of buffer data (vertices, indices, uniforms, compute data etc.). Ability to create and manually update uniform/constant buffers from C# side.
Compute shader related improvements, particularly how data is passed to them.
Remove split between TextureFormat and RenderTextureFormat, have something like “DataFormat” instead that is used in all graphics related code (similar to DXGI formats on D3D). Expose more formats than today.
Asynchronous readbacks of GPU data. Asynchronous compute.

API Overview
Note: the API is in flux, and this document might not be exact wrt whatever Unity version you’re testing with right now.
The main entry point is RenderLoop.renderLoopDelegate, which is in a form of
bool PrepareRenderLoop(Camera[] cameras, RenderLoop outputLoop);
When the render loop delegate is registered, then all rendering goes into that function, and the existing built-in rendering loops are not executed at all.
Inside of the render loop delegate, typically it would do culling for all the cameras (via the new CullResults class), and then do series of calls to RenderLoop.DrawRenderers intermixed with CommandBuffer calls to setup global shader properties, change render targets, dispatch compute shaders etc.
Overall, the design is that the C# render loop code has full control over per-camera logic (it gets all cameras as input), and all per-light logic (it gets all visible lights as a culling result), but generally does not do per-object logic. Objects are rendered in “sets” -- DrawRenderers call that specifies which subset of visible objects to render, how to sort them, and what kind of per-object data to setup.
The simplest possible render loop would look something like this:
public bool Render(Camera[] cameras, RenderLoop renderLoop)
{
  foreach (var camera in cameras)
  {
      // cull a camera
      CullResults cull;
      CullingParameters cullingParams;
      if (!CullResults.GetCullingParameters (camera, out cullingParams))
          continue;
      cull = CullResults.Cull (ref cullingParams, renderLoop);
      renderLoop.SetupCameraProperties (camera);

      // setup render target and clear it
      var cmd = new CommandBuffer();
      cmd.SetRenderTarget(BuiltinRenderTextureType.CameraTarget);
      cmd.ClearRenderTarget(true, true, Color.black);
      renderLoop.ExecuteCommandBuffer(cmd);
      cmd.Dispose();

      // draw all the opaque objects using ForwardBase shader pass
      var settings = new DrawRendererSettings(cull, camera, "ForwardBase");
      settings.sorting.sortOptions = SortOptions.SortByMaterialThenMesh;
      settings.inputFilter.SetQueuesOpaque();
      renderLoop.DrawRenderers(ref settings);

      renderLoop.Submit ();
  }
  return true;
}


Most important new scripting APIs:
// main entry point
struct RenderLoop
{
void ExecuteCommandBuffer (CommandBuffer);
void DrawRenderers (ref DrawRendererSettings);
void DrawShadows (ref DrawShadowsSettings); // similar, slightly specialized
void DrawSkybox (Camera);
static PrepareRenderLoop renderLoopDelegate;
}

// Setup and control how sets of objects are rendered by RenderLoop.DrawRenderers
struct DrawRendererSettings
{
DrawRendererSortSettings sorting;
ShaderPassName shaderPassName;
InputFilter inputFilter;
RendererConfiguration rendererConfiguration;
CullResults cullResults { set };
}

struct DrawRendererSortSettings
{
Matrix4x4 worldToCameraMatrix;
Vector3 cameraPosition;
SortOptions sortOptions;
bool sortOrthographic;
}

enum SortOptions { None, FrontToBack, BackToFront, SortByMaterialThenMesh, ... };

struct InputFilter
{
int renderQueueMin, renderQueueMax;
int layerMask;
};

// what kind of data should be set up per-object when rendering them
[Flags] enum RendererConfiguration
{
None,
PerObjectLightProbe,
PerObjectReflectionProbes,
PerObjectLightProbeProxyVolume,
PerObjectLightmaps,
ProvideLightIndices,
// ...
};

// Culling and cull results
struct CullResults
{
VisibleLight[] visibleLights;
VisibleReflectionProbe[] visibleReflectionProbes;
bool GetCullingParameters(Camera, out CulingParameters);
static CullResults Cull(ref CullingParameters, RenderLoop renderLoop);
// utility functions, like
// ComputeDirectionalShadowMatricesAndCullingPrimitives etc
}


struct CullingParameters
{
int isOrthographic;
LODParameters lodParameters;
Plane cullingPlanes[10];
int cullingPlaneCount;
int cullingMask;
float layerCullDistances[32];
Matrix4x4 cullingMatrix;
Vector3 position;
float shadowDistance;
ReflectionProbeSortOptions reflectionProbeSortOptions;
Camera camera;
}

struct VisibleLight
{
LightType lightType;
Color finalColor;
Rect screenRect;
Matrix4x4 localToWorld;
Matrix4x4 worldToLocal;
float range;
float invCosHalfSpotAngle;
VisibleLightFlags flags;
Light light { get }
}

struct VisibleReflectionProbe; // similar to VisibleLight…

The API outlined above is very much not final! Things that are very likely to change:
Considering an option to not have RenderLoop class, but instead have CommandBuffer contain functions like DrawRenderers etc., and possibly have nested command buffers too.
Culling API changes to enable more performance, i.e. jobified culling overlapping with other work.
Possibly more renderer filtering options.
More explicit “render pass” controls, instead of current “set render target” API.
Usage, inner workings, performance
The general flow is that your own render loop code is responsible for culling, and for rendering everything. Including setting up per-frame or per-renderpass shader uniform variables, managing temporary render targets and setting them up, dispatching compute shaders etc.
Visible lights and probes can be queried from the cull results, and for example their information put into compute shader buffers for tiled light culling. Alternatively, the render loop provides several ways of setting up per-object light lists for DX9-style forward rendering.
On the CPU performance side, the API is built in a way where there’s generally no per-object operations going on -- the C# side of the code is independent of the scene complexity. It typically loops over cameras, and does some iteration over visible lights to either render shadows, or to pack light data for shader usage. The rest of code that is written in C# is setting up render passes / render textures, and issuing “draw this subset of visible objects” commands.
The C++ part of code (culling, DrawRenderers, DrawShadows) is written in a high-performance style that generally just goes over tightly packed data arrays, and is internally multithreaded. Our current experiments show that with this split (high level frame setup in C#, culling/rendering in C++) we can get same or even better performance of our previous rendering loop implementations.
The C# side looks like it would create a lot of garbage-collected objects; we are looking into ways of exposing “native” (C++ side) data directly to C# without extra round-trips; in C# that would look very similar to an array that writes directly into native side memory. This is a somewhat separate topic, which we’ll talk about separately.

New built-in “HD Render Loop”
We plan to provide a built-in “HD Render Loop” targeted at modern (compute-capable) platforms. Currently it is developed with PC and PS4/XB1 consoles in mind, but we’ll be looking at optimizing it for high-end mobile platforms too. Of particular interest for mobile is optimizing it for on-tile storage / framebuffer fetch and other bandwidth-saving techniques.
Internally, shaders are written in a way that is less reliant on separate shader variants for every imaginable knob, and more using “static” (uniform based) branching, with shader variant specializations only used where that makes sense based on shader analysis / profiling on modern GPUs.
The new HDRenderLoop is being developed at github ScriptableRenderLoop (might be messy at any point, only use if you’re super-curious right now).
Lighting Features
Tiled light culling with compute shaders:
Fine pruned tiled lighting (FPTL) for deferred shaded opaque objects.
Clustered tiled lighting for forward-rendered objects and transparencies.
Rendering can be switched between deferred and forward, depending on what is better for the project.
Lights:
Usual punctual (point/spot) and directional lights.
Area lights (polygonal lights and line lights).
Correct linear lighting & PBR.
Physical light units, IES lights.
(Later) Frustum lights (i.e. bounded directional light).
Shadows:
All realtime shadows are suballocated from a single atlas.
Intuitive controls over shadow memory budget and per-light resolution overrides.
Better PCF filtering, particularly for spot/point lights.
Shadows on semitransparent objects.
GI:
Correct HDR.
Consistency with direct illumination.
(Later) Improved Shadows
Exponential shadow maps (ESM/EVSM).
Improved shadows for area lights.
(Later) Volumetric Lighting
Sky/fog atmospheric scattering model.
Local fog.
Material Features
GGX with Metal & Specular parametrizations, similar to current Standard shader.
Anisotropic GGX (Metal parametrization)
Sub-surface scattering & transmission
Clear coat
Double sided support
Good specular occlusion
Layered materials (mix & mask inputs of other materials, with up to 4 layers)
Heightmaps either via parallax or displacement tessellation
(later) Built-in LOD cross-fade / dithering
(later) Hair, Eye, Cloth shading models
Camera Features
Physically based camera parameters
Support for Unity’s PostProcessing stack
Distortion
Velocity buffer (for motion blur / temporal AA)
(later) Half/quarter resolution rendering (e.g. for particles) and compositing.
Workflow / Debug Features
Views of shader inputs (albedo, normals etc.)
Views of all intermediate buffers of rendering (lighting, motion vectors etc.)
Debug menu to control rendering of various passes

Appendix - Current Rendering Pipeline in Unity
Currently (Unity 5.5 and earlier) Unity supports two rendering pipelines for scene (forward rendering and deferred shading), and one way to render realtime shadows. Following is the description of the current pipeline in more detail:
Shadows
Shadowing system mostly works the same no matter whether the forward or deferred shading is used.
Each realtime light with shadows enabled gets a separate shadow map.
Shadow maps are traditional depth texture maps, in shaders sampled with PCF filtering (no VSM/EVSM etc. shadows).
Directional lights can use cascaded shadow maps (2 or 4 cascades); the shadow map space is divided into cascades like in an atlas.
Spot lights always use simple 2D shadowmap; point lights use a cubemap.
Shadowmap size is computed based on quality settings, screen resolution and light’s projection size on screen; or can be controlled by game developer explicitly from scripts per-light.
Cascaded shadow maps are applied in “screen space” -- there’s a separate “gather and do PCF filtering” step that produces screenspace shadow mask texture; later on regular object rendering just does one sample into this texture.
No support for receiving shadows onto semitransparent objects.
Forward Rendering
The default mode of operation is largely DX9-style “one draw call per light with additive blending”. Quality settings of the game determine how many lights per-object will be rendered in realtime; the rest are folded into a spherical harmonics (SH) representation and rendered together with other ambient lighting.
Optionally before main scene rendering: a “depth texture” rendering pass. This kicks in if scripts require it, or other features (e.g. realtime cascaded shadows) need it. Conceptually this is similar to Z-prepass; produces a texture with scene depth buffer.
Optionally before main scene rendering: a “motion vectors” rendering pass. This kicks in if scripts (e.g. motion blur or temporal AA) require it. Renders a texture of velocity vectors for objects that need them.
Realtime shadow maps are rendered before main scene rendering; all shadows are in memory at once.
Actual scene rendering pass specialized in two shader sets: “ForwardBase” (ambient/probes + lightmaps + lighting/shadows from main directional light), followed by additive blending “ForwardAdd”, that does realtime lighting one light at a time.
Deferred Shading
This is “traditional” DX9-style deferred shading: G-buffer rendering pass, followed by “render light shapes one by one” pass where each of them reads G-buffer data, computes illumination and adds it into lighting buffer.
Similar to forward rendering, an optional motion vectors pass before the G-buffer.
Reflection probes are rendered one by one similar to lights, by rendering box shapes and adding reflections into a texture.
Lights are rendered one by one, by rendering light shapes (fullscreen quad or sphere or cone) and adding reflections into a texture.
Shadow map for a light is rendered just before rendering each light, and generally discarded right after done with it.
Stencil marking is used for both lights and reflection probes to limit the amount of pixels actually computed.
Objects that don’t support deferred shading, and all semitransparent objects, are rendered using forward rendering.
Customization
It is possible to customize the above behavior to some extent, but not much. For example, Valve’s The Lab Renderer (on Asset Store) replaces the built-in behavior by (purely in C# + shaders):
Implementing a custom shadows system, where all shadows are packed into one atlas.
Custom forward rendering system, where all lights are rendered in one pass; light information is setup into custom shader uniform variables.
**** TODO support render component?(refer to Scriptable Render Loop design!)
(upgrade render command to render component?)
so now has two type component:
logic component
render component


regard different render loop as different render object
(mobile,webgl1 pc,webgl2 pc)
(forward render, defer render)

so now has two type object:
logic object
render object




so now has two type script component user can control:
logic script component
render script component(replace command buffer design?)



move buffer,bufferContainer logic to component?
(e.g. so can move animation,shadow logic all to component?)
or buffer,bufferContainer can be extensible by user?


solve:
communication between:
logic object and render object
logic component and render component


*** TODO add unit test

*** TODO solve how to extend by user:(refer to unity)


how to write own component
how to write own extension(material)
build component repository?


**** TODO extend script
user can write local script component

**** TODO extend material
user can add custom material, custom glsl, custom shaderLib_generate, custom render module(like defer, front render
module/system)
(but how to handle render worker?)




**** TODO extend glsl

***** TODO glsl use require,include?
@bhouston what about a custom webpack loader for the glsl files instead of using the raw-loader? The loader could take care of recursively resolving any #include lines in the root shader file. Any shader could be required in with e.g.:

var vert = require('three-glsl!../shaders/my-shader.vert')
var frag = require('three-glsl!../shaders/my-shader.frag')
just a thought

**** TODO extend component
user can write local/public component

add wonder_component_config.json, add "components" field.
e.g.
{
components:[
"wonder-component-aaa"
]
}

wonder should read this field and register it


public component:
(refer to typescript=>d.ts)
user should send it to public github repository
in ci, it will check and run unit test

after pass ci and merge it, it will be published to @wonder-components/xxx npm package 




*** TODO study how to separete low-level(optimized) and high-level(extensible) parts
refer to unity:
low-level:c++   high performance, multi thread
high-level:c#   extensible

*** TODO study script(integrate with engine?)
*** TODO build simple world editor(v)


*** TODO optimize sort render command(WebglRenderer.ts)
use radix sort?

refer to:
https://www.byvoid.com/zhs/blog/sort-radix
http://www.dataorienteddesign.com/dodmain/node10.html


use web worker to parallel sort:
It is possible to make this last stage of the process parallel by having each sorter ignore any values that it reads
that are outside its working set, meaning that each worker reads through the entire set of values gathering for their
bucket, but there is still a small chance of non-linear performance due to having to write to nearby memory on different
threads. During the time the worker collects the elements for its bucket, it could be generating the counts for the next
radix in the sequence, only requiring a summing before use in the next pass of the data, mitigating the cost of
iterating over the whole set with every worker. 

If your data is not simple enough to radix sort, you might be better off using a merge sort or a quick sort, but there
are other sorts that work very well if you know the length of your sortable buffer at compile time, such as sorting
networks. Through merge-sort is not itself a concurrent algorithm, the many early merges can be run in parallel, only
the final merge is serial, and with a quick pre-parse of the to-be-merged data, you can finalise with two threads rather
than one by starting from both ends (you need to make sure that the mergers don't run out of data). Though quick sort is
not a concurrent algorithm each of the sub stages can be run in parallel. These algorithms are inherently serial, but
can be turned into partially parallelisable algorithms with O(log n) latency. 



Multi-threaded sorting: Each command bucket can be sorted independently, in parallel.





*** TODO add collision(v) 
**** TODO multi thread
***** TODO add benchmark(refer to threejs,babylonjs)

*** TODO webgl2(v)

*** TODO add cpu particle system(v)
*** TODO add hdr post effect(v)(move to extension)
**** TODO design
refer to unity post process stack:
https://forum.unity3d.com/threads/new-post-processing-stack-pre-release.435581/
https://github.com/Unity-Technologies/PostProcessing/wiki
https://www.reddit.com/r/Unity3D/comments/56r2h6/unity_technologies_postprocessing_stack_image/

refer to babylonjs

*** TODO support webp image format
https://isux.tencent.com/introduction-of-webp.html


** TODO fix bug(refer to mine/Wonder.js=>commits)
//UIRenderer support set canvas size(left,top,width,height)


//fix OBJ converter=>ObjectsConverter:
refer to threejs=>OBJMTLLoader.js
use 0419.obj model
(children should be 448, but mine is 300+!)
(the g group is wrong! maybe all should rewrite!)



//model info

//model color

optimize picking:
compute center point, closest to camera

////show house:
double side?

use basic material?


//flag a,b,c


need add mesh collider

** TODO update .gltf(.wd) to 2.0

** TODO advanced multi-thread
*** TODO multi thread logic
**** TODO add action
**** TODO add collision

*** TODO SIMD



*** TODO task system
main threads(update thread, render thread)
worker threads:worker_thread_count = number_of_cores - main_thread_count


work items



sub task?


task manager

one depend?

priority



open list(not completed job) + need perform list

**** TODO optimize create render command
preallocate 10000 render commands in array

multi thread create render command

**** TODO define render data in config file

*** TODO thread pool
http://www.smartjava.org/content/html5-easily-parallelize-jobs-using-web-workers-and-threadpool
http://stackoverflow.com/questions/13574158/number-of-web-workers-limit
** TODO use optimize-js to package
https://github.com/nolanlawson/optimize-js


////***** TODO add package unit tests
** TODO optimize shaders
https://www.zhihu.com/question/22595954/answer/61277904
study:
tag math+visibility组件
shader cache收集系统


Windows performance toolkit




only iterate shader lib once



看来是根据序号得到顶点变量名
这个处理的好，这样通过查询来获得变量名，就不要先保存这些变量名了:
refer to three:
function fetchAttributeLocations( gl, program, identifiers ) {

		var attributes = {};

		var n = gl.getProgramParameter( program, gl.ACTIVE_ATTRIBUTES );

		for ( var i = 0; i < n; i ++ ) {

			var info = gl.getActiveAttrib( program, i );
			var name = info.name;

			// console.log("THREE.WebGLProgram: ACTIVE VERTEX ATTRIBUTE:", name, i );

			attributes[ name ] = gl.getAttribLocation( program, name );

		}

		return attributes;

	}


function WebGLUniforms( gl, program, renderer ) {

	UniformContainer.call( this );

	this.renderer = renderer;

	var n = gl.getProgramParameter( program, gl.ACTIVE_UNIFORMS );

	for ( var i = 0; i < n; ++ i ) {

		var info = gl.getActiveUniform( program, i ),
			path = info.name,
			addr = gl.getUniformLocation( program, path );

		parseUniform( info, addr, this );

	}

}



** TODO skin optimize
*** TODO use blender to build skin animation


fix yuan bao problem:
the animation and the static model's rotation is not the same!(animation has rotate(0,-90,0)!)
(
gltf is correct(monster is correct)(by compare with threejs)

but fbx is wrong!(xsi_man_skinning.fbx)(compare with threejs=>webgl_loader_fbx.html)
maybe the bind shape matrix is wrong? need parse!?
# parse bind shape matrix:
# http://www.gamedev.net/topic/574309-solved-fbx-animation-problems/
# refer to babylonjs=>SkinInfo.cpp=>bindPoses ?)




*** TODO support multi animations in one fbx
pass fbx=>converter=>multi skin animations!:
use blender to add multi animations of one model in one .fbx file
learn how to separate and combine character and its props animations!


*** TODO optimize skin
fbx:
  parse bind shape matrix:
  http://www.gamedev.net/topic/574309-solved-fbx-animation-problems/
  refer to babylonjs=>SkinInfo.cpp=>bindPoses ?




optimize: 
not update tranlation,scale(pre handle key frame data)



write to texture:
judge vertex texture


//add basic optimize


add render test


optimize: 
//if bindShapeMatrix is identify, set it null and not multiply

other "todo" optimizes


optimize:
query max uniform data arr count



compute in gpu
1) Make sure that the size of the bones array is correct. Often times, you will find that part of the mesh is skinned fine while the other parts are not skinned correctly. If so make sure the size of the bones array is correct.  

There are two things that you have to be careful about.





*** TODO publish





** TODO fbx support morph anim

*** TODO pass skin + morph(use blender)

*** TODO publish


** TODO support animation blend

*** TODO publish

** TODO support animation control(using action to control)
refer to unity:
https://docs.unity3d.com/Manual/AnimationSection.html



support time limit logic(e.g. isTimeExceed5000)

support frame control

*** TODO refactor:extract AnimationEngine and move out to be a new project

*** TODO publish


** TODO finish phone=>todo
*** TODO use compress texture?

support .pvr in ios

**** TODO use blender to generate compress texture

*** TODO audio add more control(play one time, stop...)


*** TODO publish 
** TODO optimize(beta)
*** TODO read references
https://developer.nvidia.com/nvidia-gpu-programming-guide

http://www.cnblogs.com/ghl_carmack/p/4107042.html


*** TODO cpu optimize
optimize clone,extend,deepextend:
https://cnodejs.org/topic/56c49662db16d3343df34b13
use Object.assign()
https://github.com/Microsoft/TypeScript/issues/3429
( typescript2.2=>extend)
https://github.com/Microsoft/TypeScript/pull/13604






optimize transform:
optimize Transform=>state?

check is the same in setting position,scale,rotation, localXXX(new value === old value, not set,dirty?)



optimize shader:
staticly compile shader param of libs to one large collection of the one entityObject
(so no need to iterate the shader libs at runtime)


*** TODO memory optimize
add global Temp class, for save temp matrix,vector...
(refer to bjs=>math.ts=>Temp class)

use memory pool instead of Temp class?
(refer to sk_design=>MemoryUtil,MemoryPool)



show memory info:
refer to sk_design=>WebGLRenderer=>dump method


optimize Vector2/3/4:
remove "values" attr


optimize hash=>removeChild



memory optimize:
https://www.scirra.com/blog/76/how-to-write-low-garbage-real-time-javascript
http://blog.tojicode.com/2012/03/javascript-memory-optimization-and.html

http://www.cocos2d-x.org/wiki/How_to_Optimise_Memory_Usage
http://www.cocos2d-x.org/wiki/Memory_Management_of_JSB

http://stackoverflow.com/questions/13914959/three-js-memory-management


http://www.html5gamedevs.com/topic/6903-memory-consumption-difference-between-111-and-112-beta/




use instance pool to re-use render commands

*** TODO specific optimize
**** TODO octree optimize
**** TODO instance optimize
////**** TODO shadow optimize

*** TODO optimize skeleton animation
把所有不同的角色的骨骼相关的矩阵和变换信息写入到纹理里(refer to playcanvas, threejs)
(fallback:if not support vertex texture, pass uniform data instead)
http://ftp.opengpu.org/forum.php?mod=viewthread&tid=18164&extra=page%3D1

http://http.developer.nvidia.com/GPUGems3/gpugems3_ch02.html

https://github.com/mrdoob/three.js/issues/3187


use Skinned Instancing

use quaternion for rotate skeleton



*** TODO more?


** TODO finish projects to apply engine(beta)
(add needed feature from 0.x engine version!!!)

*** TODO game code should not import not used code
not initData/add init,dispose together?
or game code will not import code except initData?

*** TODO in pc
**** TODO write a rpg game(spirit game)(spirit dream?)(can get resource about 3d engine, meditation, spirit, pi gu, juexing...)
refer to https://github.com/pissang/qtek-bootcamp 

use blender to generate assets


**** TODO build custom outer scene(octree+lod+direction light+collision+shadowmap+terrain+water(mirror reflection, refraction) + morph animation player character)
***** TODO support physics heightmap
add physics box,sphere
player can collision with these box,sphere







add demo:
refer to babylonjs=>Samples/Scenes/WorldMonger/

refer to http://www.babylonjs-playground.com/#E6OZX#7
add mix map, normal map

layer texture(blend)(use blend map)

water

cloud

sky dome


add tree

add grass

shadow(shadowMap, lightMap)




**** TODO build custom room scene(point light+lightmap+shadowmap+cubemap reflection+articulated camera+collision)





*** TODO in mobile
**** TODO run in mobile
***** TODO rewrite bainian project(use require:cmd/nodejs)
****** TODO fix in mobile
run in mobile environment:
fix skin animation:(first animation is not play completely)
(due to elapsed !== _beginElapsedxxx at the first update!)
refactor and test: save begin time
articulated also has the bug!?


build mobile test environment



fix:
set pixel ratio in mobile => set style width/height?
         view.width = view.width * window.devicePixelRatio;
         view.height = view.height * window.devicePixelRatio;
         view.styleWidth = view.width + "px";
         view.styleHeight = view.height + "px";

set viewport?:
gl && gl.viewport(
    camera.viewPort[0] / window.devicePixelRatio,
    camera.viewPort[1] / window.devicePixelRatio,
    camera.viewPort[2] / window.devicePixelRatio,
    camera.viewPort[3] / window.devicePixelRatio
);



optimize:
hongbao=> parse and assemble geometry is slow
(compress position,joint,weight... to one buffer)





fix:
maoke=>arcball camera=>roll up/down is wrong!

unify Animation,SingleLayerKeyFrameAnimation,MultiLayerKeyFrameAnimation=>play=>params
refactor Animation,SingleLayerKeyFrameAnimation,MultiLayerKeyFrameAnimation=>playOneTime(move to Animation)


optimize:
maoke=>arcball camera=>roll is very slow!




enhance mobile debug:
rewrite console:
http://eclipsesource.com/blogs/2012/08/14/debugging-javascript-on-android-and-ios/
use vconsole:
https://www.qianduan.net/vconsole-open-source/

show profile info



feat: Collider add "setFromVertices"
















optimize:
//solve switch cat slow:
//precompute cat2 bone matrix(update(0)?)


//play sound after show 






















**** TODO mobile optimize
http://www.cnblogs.com/ghl_carmack/p/5401906.html
http://www.cnblogs.com/gameknife/p/3515714.html

https://developers.google.com/speed/docs/insights/mobile

***** refer to hongbao:
optimize:
show other model in later(show bainian animation of another model when click on first model)

optimize:
parse and assemble hilo3d(now parse geometry is very slow)



optimize hongbao in ios(also in android?):
optimize model=>antialias in android,ios




optimize hongbao=>03b => cat(xxxSurface_251(66?))=>normal compute:
isn't correct!


**** TODO optimize asset
refer to hongbao:
optimize skin animation
optimize model geometry


**** TODO tao fu wa
**** TODO simple room scene(player with skin animation to navigator)
**** TODO simple outer scene





*** TODO in both
**** TODO car demo(replace material)
**** TODO physics demo(like tao fu wa)
**** TODO jiao's picture demo(particle, picking, hdr, reflection)


*** TODO fix problems
*** TODO optimize

** TODO publish v1.0.0
(may not contain all feature of v0.x version!)

author be company name
author: add company website

banner=>@link change to company repo link


not use multi thread render defaultly(close it)
(engine in editor should close it too!)


update Wonder-Editor->wonder.js version

*** TODO change license
wonder-editor: use gpl?bsd?

*** TODO publish types to definition repo
publish wonder.js types
publish wonder-fantancy-land types

update wonder-commonlib, wonder-frp types

*** TODO pass run in windows=>ie11
fix:
instance_xxx_shadow_xxx
merge_model




*** TODO other



increase runtime test rate from 92% to 95%


can work from the scratch
(runtime, package, test, converter, height generater)
(commonLib, frp)


add wonderjs website

add wonderjs blog

add wonderjs forum

add wonderjs online demo


write document, tutorials:



support full screen(refer to babylon.engine.ts=>450 line)


** TODO optimize cpu(v0.5.8)
//render target renderer(e.g. Mirror,Refraction,DynamicCubemap, ...) and procedural renderer, shadowMap(refer to
babylonjs=>Samples/Demos/Instances/instances.js line 100), VideoTexture,   add "refreshRate", "refresh control"(like
stop refresh,start refresh, refresh(count):refresh the specify times
(Math.ceil, 1=>refresh every frame; 2=>refresh every 2 frames;0=>refresh only in the first frame, ...)
(add refresh rate counter)





use texture matrix to replace repeat,part data



move BoxGeometry, ...(except ModelGeometry,CustomGeometry) computation
to worker
(refer to <<webgl insights>> p81)





optimize math library(e.g., Matrix4,Matrix3...):
use TDL, Closure, and gl-matrix instead? or modify the existed library
based on them?

From the benchmark it is clear that TDL, Closure, and gl-matrix are
the top contenders in terms of performance as tested on a MacBook Pro
(OS X 10.9.5, 2.4 GHz Intel Core i7, 8 GB 1333 MHz DDR3).  





//data orient driven(refer to game engine germ 1/2)



regard octree,lod as benchmark test



https://blogs.msdn.microsoft.com/eternalcoding/2013/05/21/benchmarking-a-html5-game-html5-potatoes-gaming-bench/
https://blogs.msdn.microsoft.com/eternalcoding/2015/01/07/javascript-shoud-i-have-to-cache-my-arrays-length/
https://blogs.msdn.microsoft.com/eternalcoding/2015/02/02/using-user-mark-to-analyze-performance-of-your-javascript-code/




https://www.smashingmagazine.com/2012/11/writing-fast-memory-efficient-javascript/
https://msdn.microsoft.com/en-us/library/windows/apps/hh781219.aspx
https://channel9.msdn.com/Events/Build/2013/4-313
http://malideveloper.arm.com/downloads/GDC14/Thursday/10.30amWebGL.pdf




use webgl-inspector=>highlights to see duplicate setting uniforms

Note that uniforms are specific to programs and they are remembered by the programs, so you don't have to re-set them
every time you switch programs! 




not create duplicate textures







BufferContainer=>getChild=>apply:
remove @cache
use {} instead of Hash



optimize ArticulateAnimation=>_updateTargets





ActionManager=>update
script=>update





optimize benchmark_shadow test:
optimize memory
camera vpMatrix add cache






optimize instance with octree,lod

optimize:
show 10000 spheres with 60fps(instance)
show 20000 spheres with 60fps(instance + lod)
show 40000 spheres with 60fps(instance + octree)
show 60000 spheres with 60fps(instance + octree + lod)

////only render visable instance

////if not support instance, optimize ethier
(refer to bjs(babylonjs))

////*** TODO optimize: cache all uniform/attribute position when init(then look up the cache table to get the position when send glsl data)
////refer to babylonjs=>effect.ts, engine.ts=>getUniforms/getAttributes method








support merge instancing?
http://www.humus.name/Articles/Persson_GraphicsGemsForGames.pdf
http://hacksoflife.blogspot.com/2013/01/instancing-for-bricksmith.html

When reducing the number of draw calls there are two standard approaches. Multiple
instances of a single mesh is typically done with regular instancing. If there are multiple
meshes, but a single instance of each, they can be merged into a single vertex and index
buffer and drawn with a single draw call. However, sometimes you want to draw multiple
meshes, with multiple instances of each, and each with their own transforms or other instance
data. With instancing this results in multiple draw calls. With the standard merging approach
you need to duplicate the vertex data.
We came up with an approach that combine the benefits of merging and instancing such that
you can draw it all with a single draw call without duplicating vertex data. Thus, for the lack of a
better name, it can be referred to as Merge-Instancing.














optimize octree sample: frustum(especially arcball camera), ray picking, collision

bug:
if add/remove EntityObject, will the octree rebuild?




optimize water,terrain



optimize mirrorMirror, dynamicCubemapTexture




optimize lod

reduce composite layers time(when move camera to switch geometry in lod sample):
http://www.chromium.org/developers/design-documents/gpu-accelerated-compositing-in-chrome
http://www.html5rocks.com/en/tutorials/speed/scrolling/
https://developer.chrome.com/devtools/docs/timeline
http://www.html5rocks.com/zh/tutorials/speed/layers/



optimize collision:
add layers:
http://docs.unity3d.com/Manual/LayerBasedCollision.html








optimize shadow(especially point shadow)
bug: 
in collision_box sample, why shadow break when move box down to near the edge of screen?(not caused by light=>shadowCameraXXX)

test light move



not bind color to frame when build shadow map?

not bind and send uniform when build shadow map





optimize:
cache camera=>vpMatrix
shadow layer

////not bind texture when build shadow map










*** TODO other

//if the texture is the same there is NO rebinding:

https://github.com/BabylonJS/Babylon.js/blob/master/Babylon/babylon.engine.ts#L1961



//move "create program" logic out of shader?



**** TODO optimize refer to <<OpenGL Insights>>  39 chapter

Group objects in buffers based on data format (type and layout) and update
frequency.

Ensure that appropriate buffer usage flags are used.

Use static buffers and fully specify the contents of buffers before draw time.


Use immutable textures when available?
If EXT texture storage is not supported, ensure that a complete texture is
created and consistently defined. 


Avoid redefining the format or size of existing textures, and create a new tex- ture instead. 


Use packed depth-stencil for combined depth and stencil support.

Avoid masked clear operations.

Avoid using complex conditional statements and loops with a high maximum number of iterations in shaders. 



**** TODO z prepass

not bind and send uniform when z prepass
(bindless or uniform blocks are ways of minimizing these)






***** TODO WebGLRenderer: sort opaque objects from front to end

On IMR GPUs, this extra bandwidth consumption and fragment work can be limited by sorting and rendering geometry from
front to back (see Figure 24.4).  

An additional heuristic for games is to render the player character first and the sky-box last  









**** TODO update profiling tool
refer to <<OpenGL Insights>> 36 chapter

Intel Graphics Performance Analyzers (GPA):(can use only in windows?)
http://www.intel.com/software/gpa

WebGL Inspector shows the WebGL side, and Frame Analyzer shows the post-translation DirectX equivalent 

start Intel Graphics Performance Analyzers:
Fortunately, starting Chrome with a --no-sandbox flag allows GPA to at- tach to the correct rendering process and
trigger frame captures.  





use [[https://software.intel.com/en-us/gpa/details][Graphics Performance Analyzers]] ?


**** TODO use Map/Set to update Hash/Collection



** TODO optimize memory, cg(v0.5.9)




vertex compress
https://cesiumjs.org/2015/05/18/Vertex-Compression/
compress billboard instance data:
https://cesiumjs.org/2015/10/28/Billboard-Instancing/





optimize benchmark_2000_boxes_forRunTest(add action component)




This kind of unwanted memory churn is usually created by algorithms
that compute intermediate values that are quickly thrown away. 

Listing 4.7 A memory-inefficient linear interpolation function.
Cartesian3.add = function(left, right) { var x = left.x + right.x;
var y = left.y + right.y;
var z = left.z + right.z;
return new Cartesian3(x, y, z); };
Cartesian3.multiplyByScalar = function(value, scalar) {
var x = value.x * scalar;
var y = value.y * scalar;
var z = value.z * scalar;
return new Cartesian3(x, y, z); };
Cartesian3.lerp = function(start, end, t) {
var tmp = Cartesian3.multiplyByScalar(end, t);
var tmp2 = Cartesian3.multiplyByScalar(start, 1.0 - t); return Cartesian3.add(tmp, tmp2);
};


Every call to lerp allocates three objects: two intermediate
Cartesian3 instances and the result instance. While a microbenchmark
of 100,000 calls takes about 9.0 milliseconds in Firefox, it doesn’t
expose a problem with garbage collection because the memory is not
cleaned up until after our benchmark has already completed. 
We can remove the extra memory allocation by using two simple
techniques. First, we require users to pass in an already allocated
result parameter to avoid having to create a new instance every
time. Second, we use module-scoped scratch parameters in calls to add
within lerp. 

Listing 4.8 Memory-efficient linear interpolation using result parameters and scratch variables.
Cartesian3.add = function(left, right, result) {
 result.x = left.x + right.x;
result.y = left.y + right.y;
result.z = left.z + right.z;
return result; };
Cartesian3.multiplyByScalar = function(value, scalar) {
 result.x = value.x * scalar;
result.y = value.y * scalar;
result.z = value.z * scalar;
return result; };
var tmp = new Cartesian3(0, 0, 0); var tmp2 = new Cartesian3(0, 0, 0);
Cartesian3.lerp = function(start, end, t, result) { Cartesian3.multiplyByScalar(end, t, tmp); Cartesian3.multiplyByScalar(start, 1.0 - t, tmp2); return Cartesian3.add(tmp, tmp2, result);
};




clean memory
http://stackoverflow.com/questions/23598471/how-do-i-clean-up-and-unload-a-webgl-canvas-context-from-gpu-after-use





For performance, avoid object allocation in the render loop. Reuse objects and arrays where possible, and avoid built-in
array methods such as map and filter. Each new object creates more work for the Garbage Collector, and in some cases, GC
pauses can freeze an application for multiple frames every few seconds. 






release when need:
manage ProgramTable,BufferTable:
add references count
check references to decide whether to dispose the one whose referencs is 0


https://blogs.msdn.microsoft.com/eternalcoding/2013/09/04/reducing-the-pressure-on-the-garbage-collector-by-using-the-f12-developer-bar-of-internet-explorer-11/


http://goocreate.com/learn/reducing-memory-usage/
https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management
http://www.html5rocks.com/en/tutorials/speed/static-mem-pools/


use Array instead of Collection in the key path?

memory allocate
http://www.mystengine.com/blog/?p=59
http://www.cnblogs.com/dreams/archive/2007/03/25/687310.html





** TODO optimize gpu

*** TODO optimize glsl
https://www.opengl.org/wiki/GLSL_Optimizations


[[http://aras-p.info/blog/2011/08/17/fast-mobile-shaders-or-i-did-a-talk-at-siggraph/][Fast Mobile Shaders]]


When we suspect that our application is shader-bound, we can always
perform a simple test to see if this really is the case: Replace all
of the shaders with trivial ones that only render a single
recognizable color and measure the performance. If the performance is
significantly changed, the application is likely shader-bound—either
by GPU computa- tion or by texture fetches performed by the shaders. 




*** TODO other

http://malideveloper.arm.com/downloads/GDC14/Thursday/10.30amWebGL.pdf



////** TODO optimize: batch draw calls(v0.5.10)
use stride in gl.vertexAttribPointer(refer to Wozlla Engine)




render to target support mipmaps(refer to bjs)
*** TODO Vertex cache optimization 
refer to <<OpenGL InSights>> 26 chapter: Indexing Multiple Vertex Arrays
This chapter shows a simple solution to convert nonindexed data into an indexed form, allowing its use in an efficient
way with many file formats such as OBJ, X, VRML, and COLLADA. 

refactor obj,md2 indices build?



A number of algorithms can be found in the literature for reorganizing the indices in order to get a better
post-transform cache usage. 
In particular, I recom- mend nvTriStrip, which is slow but ready-to-use, and Tom Forsyth’s
algo- rithm [Forsyth 06], which runs in linear time. 

https://www.opengl.org/discussion_boards/showthread.php/167481-Vertex-cache-optimization

http://tomforsyth1000.github.io/papers/fast_vert_cache_opt.html

https://github.com/vivkin/forsyth
http://www.cnblogs.com/ghl_carmack/p/4107042.html


*** DONE VAO

webgl 2? just use extension in webgl 1!
To save a lot of API calls, use vertex array objects (VAOs) or interleave static vertex data. 




that can significantly improve per- formance on mobile devices

VAOs are available in WebGL 1.0 with the OES_ vertex_array_object
extension, which is widely supported on mobile devices. As of early
2015, more than 80% of smartphone and tablet clients recorded by
WebGL Stats have it 



If vertex array objects (VAOs) are supported, then we build one for
each combination of vertex buffers and index buffer present in the
DrawParameters objects. As we share the buffers between many different
geometries, the actual number of combinations is usually quite
low. This allows us at dispatch time to simplify all the buffer checks
to a single equality comparison between the current VAO and the
previous one. Even when the VAOs are dif- ferent, setting them with
WebGL is cheaper on the CPU than setting all the different buffers and
vertex pointer attributes, which makes them a big win for complex
scenes.


Adding a fallback for devices without VAO support is also
straightforward. Let’s call the code that binds buffers and sets
vertex attrib pointers related to a specific mesh the binding
block. If VAOs are supported, the code should initialize the VAO of
each mesh using the binding block. Then, when the mesh is drawn, the
code either binds the VAO if VAOs are supported, or executes the
binding block if VAOs are not supported. The only case where this
becomes more complicated is when there’s a different number of active
vertex attribute arrays for different meshes—then the code should add
disable- VertexAttribArray calls where appropriate. For a complete
code example, see an explanation of VAOs* or an implementation of a
fallback path in SceneJS
(https://github.com/xeolabs/scenejs/blob/v4.0/src/core/display/chunks/geometryChunk.js)




Lowering the number of vertex buffers helps to reduce CPU usage if
VAOs are not a good fit for the code for some reason. This can be done
by interleaving different types of vertex data for the same object: If
we have, for example, positions, texture coordinates, and normals for
each vertex, they can all be stored in the same vertex buffer in an
interleaved fashion. In our CPU-bound drawing test that uses four
vertex attributes, interleaving the attributes increased the FPS
around 4%. The downside is that interleaving the data needs to be
either handled by the content creation pipeline or done at load time;
the latter may marginally slow down loading. Interleaving three
attributes for a million vertices in a tight JS loop had a cost of
around 200 ms on a Nexus 5 (2013 phone). 




http://blog.tojicode.com/2012/10/oesvertexarrayobject-extension.html

http://www.openglsuperbible.com/2013/12/09/vertex-array-performance/

 

*** TODO optimize from <<WebGL Insights>>

For portability, space requirements of varyings and uniforms within the limits of the GLSL ES spec. Consider using
vec4 variables instead of float arrays, as they potentially allow for tighter packing. See A.7 in the GLSL ES spec. 










When using an RGB framebuffer, always implement a fallback to RGBA for when RGB is not supported. Use
gl.checkFramebufferStatus. 




If shrinking the browser window results in massive speed gains, consider using a half-resolution framebuffer during
mouse interaction. 



Use OES_element_index_uint to draw large indexed models with a single draw call.



need change???
The textureProj GLSL function, vec4 color = textureProj(sampler, uv.xyw);, can be simulated with vec4 color =
texture(sampler, uv.xy/uv.w) 



**** TODO ANGLE optimize(refer to <<WebGL Insights>>=>chapter 1):
- Avoid use of gl.TRIANGLE_FAN, as it may be emulated in software.

- Create new textures, rather than changing the dimensions or format of old ones.
  - if only the pixel data contained in a texture need to be updated, it is best to reuse the texture—the additional
overhead is only incurred when updat- ing texture format or dimensions, because these require redefinition of the mip-
map chain. 

- Do Not Perform Clears with Scissors or Masks(color mask,stencil mask) Enabled
so check and warn info when clear

- Avoid Render Wide Lines as Polygons
(ANGLE does not support line widths greater than 1.0, commonly called “wide” lines)




- Avoid Uint8Array Data in Index Buffers


- Avoid 0xFFFF in 16-Bit Index Buffers
  

- Always Specify the Fragment Shader Float Precision

- Do Not Use Rendering Feedback Loops
(In the OpenGL APIs, attempting to write to and sample from the same texture or renderbuffer in a rendering operation is
considered a rendering feedback loop)


- Don’t Use Extensions without Having a Fallback Path

- Use Immutable Textures When Available (use EXT_texture_storage extension to use texStorage* command instead of
  texImage* command)
Historically, OpenGL and WebGL textures had to be created one mip level at a time. OpenGL does this via glTexImage*, a
method that allows users to cre- ate internally inconsistent textures, considered by the GL to be “incomplete.” This
same method is what is available to developers in WebGL, as texImage*. By contrast, Direct3D requires that users define
the dimensions and format of their entire textures at texture creation time, and it enforces internal consistency. 

Because of this difference, ANGLE must do a considerable amount of bookkeep- ing and maintain system memory copies of
all texture data. The ability to define an entire texture at creation time did later get introduced to OpenGL and its
related APIs as immutable textures, which also enforce internal consistency and disallow changes to dimensions and
format. Immutable textures came to OpenGL ES 2.0 with EXT_texture_storage [Khronos 13a], and they are included in the
core OpenGL ES 3.0 specification and the WebGL 2 Editor’s Draft specifica- tion. When immutable textures are available
via extension or core specification, some of ANGLE’s bookkeeping can be avoided by using the texStorage* com- mands to
define textures. 


- Use RED Textures instead of LUMINANCE(use EXT_texture_rg extension [Khronos 11] to use the RED and RG formats)
(simply using RED textures in place of LUMINANCE and RG in place of LUMINANCE_ALPHA when using ANGLE with APIs that
support them) 

In WebGL and unextended OpenGL ES 2.0, the only option developers have for expressing single-channel textures is the
LUMINANCE format, and LUMINANCE_ALPHA for two-channel textures. The EXT_texture_rg extension [Khronos 11] adds the RED
and RG formats, and these formats become core functionality in OpenGL ES 3.0. The formats also appear in the WebGL 2
Editor’s Draft specification. Meanwhile, Direct3D 11 has dropped all support for luminance textures, providing only red
and red-green formats [MSDN 14a]. This may seem to be a trivial difference—a channel is a channel—but sampling from a
luminance texture is performed differently than from textures of other formats. The single channel of a luminance
texture is duplicated into the red, green, and blue channels when a sample is performed, while sampling from a RED
texture populates only the red channel with data. Similarly, the second channel of a LUMINANCE_ALPHA and an RG texture
will populate only the alpha and green channels in a sample, respectively. To support luminance formats against Direct3D
11, rather than alter the swizzle behavior in shaders, ANGLE instead expands the texture data to four channels. This
expansion, and the associ- ated additional memory and texture upload performance costs, can be avoided by developers
keen for clock cycles by simply using RED textures in place of LUMINANCE and RG in place of LUMINANCE_ALPHA when using
ANGLE with APIs that support them. 



- Avoid Full-Texture Swizzle
Texture swizzling is an OpenGL ES 3.0 feature which allows a texture’s compo- nents to be sampled in a different order,
using the TEXTURE_SWIZZLE_R, TEXTURE_SWIZZLE_G, TEXTURE_SWIZZLE_B, and TEXTURE_ SWIZZLE_A texture parameters. This is
most often used to read RGBA textures as BGRA, or vice versa, and can also be used to replicate components as with
luminance textures. This feature is, however, not supported by Direct3D 11. Even though it appears a seemingly simple
operation to perform during the shader translation, it is actually not feasible to determine which textures are sampled
where, because samplers can be passed from function to function as parameters, and the same texture sampling function
can be used to sample various different textures. ANGLE therefore swizzles the texture data itself. This consumes some
memory and incurs some overhead at texture upload. These costs can be avoided by not changing the TEXTURE_SWIZZLE_R,
TEXTURE_SWIZZLE_G, TEXTURE_SWIZZLE_B, and TEXTURE_SWIZZLE_A texture parameters from their defaults. If necessary, use
multiple shader variants to account for dif- ferent texture component orders. 




***** not use

- Avoid Uniform Buffer Binding Offsets
Uniform buffer objects (UBOs), newly added in OpenGL ES 3.0, are bound objects which store uniform data for the use of
GLSL shaders. UBOs offer benefits to developers, including the ability to share uniforms between programs and faster
switching between sets of uniforms. OpenGL ES 3.0 also allows UBOs, much like other buffer objects, to be bound at an
offset into the buffer, rather than just the buffer head. Direct3D, on the other hand, does not support referencing its
analogous structure, constant buffers, until Direct3D 11.1, with the addition of the VSSetConstantBuffers1 method [MSDN
14d]. Offsets are supported with a software workaround on all hardware of lower feature levels. Developers can avoid any
performance penalty associated with this workaround by binding UBOs at offset 0 only. 




***** need more understand!
- Avoid Three-Channel Uint8Array/Uint16Array Data in Vertex Buffers(can use four-channel with Uint32Array data)
Direct3D has limited support for three-channel vertex formats. Only 32-bit three- channel formats (both integer and
float) are supported natively [MSDN 14a]. Other three-channel formats are expanded by ANGLE to four-channel internally
when using a Direct3D backend. If the vertex buffer usage is dynamic, this con- version will be performed each time the
buffer is used in a draw. To avoid the expansion, use four-channel formats with 8- or 16-bit types. 


- Avoid Integer Cube Map Textures
Cube maps with unnormalized integer formats are not supported by Direct3D 11 [MSDN 14c]. The ANGLE team hasn’t
encountered any uses for it, which may be the reason it was left out of D3D11, but it is a feature of OpenGL ES 3.0 and
gets tested by the conformance tests. ANGLE therefore must emulate it in ANGLE’s ESSL to HLSL translator. The cube
texture is replaced by a six- layer 2D array texture, and the face from which to sample, and at what loca- tion, is
manually computed. Rather than unnormalized integer formats, we recommend using normalized integer formats for cube
maps. If integer values are expected, multiply the sampled value by the maximum integer value, and round to the nearest
integer. For example, for signed 16-bit integers: int i = int(round(32767 * f)); 



- Beware of Shadow Lookups in 2D Array Textures
Our final recommendation is a minor one, because the range of hardware affected is relatively small. Shadow comparison
lookups are a feature introduced in OpenGL ES 3.0. These texture lookups can perform prefilter comparison of depth data
contained in a texture against a provided reference value. ES 3.0 also intro- duces new texture types, including 2D
texture arrays. Where these two features intersect, a caveat emerges. Direct3D 11 does support shadow lookups for 2D
tex- ture arrays—but not at feature level 10_0 [MSDN 14e]. For this reason, ANGLE must either exclude feature level 10_0
hardware from ES 3.0 support or implement a workaround, with potential performance penalties. If the latter approach is
cho- sen, developers may encounter performance issues on Direct3D 10.0 hardware. If the former approach is chosen
instead, then OpenGL ES 3.0 would not be avail- able on this hardware at all. 






**** TODO firefox implement webgl(refer to <<WebGL Insights>>=>chapter 2):

- Each drawElements call can only work with one index
type anyway. Keep separate index types in separate element array
buffers. 

Using the same element array buffer with multiple index types only
requires the implementation to maintain separate trees for each type;
there are three pos- sible types so there can be up to three trees to
maintain for a given element array buffer, which multiplies by three
the memory usage and speed overhead. Just don’t do it. There is no
good reason to: Each drawElements call can only work with one index
type anyway. Keep separate index types in separate element array
buffers. 


- So if you don’t need to update a frame, don’t it, don’t even call clear. 

The first conclusion of this discussion is that if you don’t need to
update a frame, avoid- ing re-rendering it will save not only the time
it takes to render it, but also a lot of inter- nal compositing work
and synchronization. So if you don’t need to update a frame, don’t
touch it, don’t even call clear. 

**** TODO refer to <<WebGL Insights>>=>chapter 4:
This means that if we want to expose a property on an object, it’s
faster to make it a public field rather than abstract it behind get
and set methods 



**** TODO refer to <<WebGL Insights>>=>chapter 8(mobile chapter):

An application should not have unnecessary “get” calls of any kind,
especially getError, or frequent calls requiring synchronization like
readPixels, flush, or finish.  


***** Reducing Bandwidth Usage

The more obvious ways to reduce bandwidth are reducing texture or
framebuffer reso- lution.  



optimize full-screen effects
Implementing full-screen effects in an efficient way or avoiding them
altogether can also enable huge bandwidth savings [McCaffrey 12;
Pranckevičius 11]. In particular, it is better to combine different
postprocessing filters into a single shader or add simple post-
processing effects directly into the shaders used to render geometry,
when possible. 



Using lots of small polygons also costs bandwidth on tiler
architectures, since they need to access the vertex data separately
for each tile [Merry 12]. Optimizing models to minimize the vertex and
triangle count helps on these GPUs. 


**** TODO refer to <<WebGL Insights>>=>chapter 10(Turbulenz Engine):

cull lights:
For lights, we may go an extra step by projecting the bounding box
into the screen to calculate how many pixels it would actually light,
discarding the light or disabling its shadows’ maps depending on its
contribution to the scene. 


**** TODO refer to <<WebGL Insights>>=>chapter 14:

When the user spins the model around its turntable using a touch
interface, a smooth frame rate is achieved by rendering to a
low-resolution framebuffer (left). When the user lifts her fingers, we
redraw the model in full resolution (right). 

Listing 14.7 Low-fidelity/high-fidelity modes for glass effect.
MyEngine.Buddha = function() { this.framebuffers = {lo: null, hi: null}; this.textures = {lo: null, hi: null};
};
MyEngine.Buddha.draw = function(gl, turntable) {
var texture, canvas = gl.canvas;
if (turntable.state = = turntable.states.Resting) {
//Use a full-resolution framebuffer:
texture = this.textures.hi; gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffers.hi); gl.viewport(0, 0, canvas.width, canvas.height);
} else {
//Use a half-resolution framebuffer:
texture = this.textures.lo; gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffers.lo); gl.viewport(0, 0, canvas.width/2, canvas.height/2);
}
    //...draw Buddha to offscreen surface...
    gl.viewport(0, 0, canvas.width, canvas.height);
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    gl.bindTexture(gl.TEXTURE_2D, texture);
    //...draw fullscreen triangle to canvas...
    gl.bindTexture(gl.TEXTURE_2D, null);
};
￼

** TODO optimize from <<游戏引擎架构>>
资源运行时管理：
通过记录引用数来释放资源（p265)

增量时间：
设置上限（p292)

调试：
//开发绘制直线、坐标轴等调试绘图api

//研究data driven engine(p656)

//改进GameObject=>update:
use batch update(p679)


//sky box:
close depth write(p441)



** TODO reference
http://www.cppblog.com/liangairan/archive/2013/03/23/198749.html

** TODO add debug Panel(second version)
use ui component to draw

refactor:
add DebugDrawer class


add more info like bjs




** TODO improve transform
learn GPU Pro 5=>managing transforms in hierarchy



** TODO advanced defer shading
*** TODO gbuffer
how to dynamic set expand gbuffer's value(e.g. store emission color or not)???
support pass specular(if has specular map) in gbuffer or not in
support pass emission color in gbuffer or not in



defer shading:
send emission color




*** TODO optimize
**** TODO optimize
***** TODO gbuffer optimize
use the least amount of memory by lowering precision, reconstructing position from depth, packing values together, using
different distributions, and so on. 




compressing normals to 2 channels:
http://aras-p.info/texts/CompactNormalStorage.html
e.g. ???
    vec3 normal = vec3(gb0[3], gb1[3], 0.0);
    normal.z = (1.0 - normal.x*normal.x - normal.y*normal.y);
    normal.z *= sign(dot(normal, u_cameraPos - pos));
    normal = normalize(normal);




not store specularColor, keep it be #ffffff:
Another compression optimization is to drop specular color off. Non metals rarely have colored specular and metals does
not have albedo. So for metals you can use albedo as spec color and for non metals you just need single channel specular
intensity. 



reconstructing position from depth



***** TODO use 3d texture for tile defer shading?
to store light index list and light grid

https://github.com/WebGLSamples/WebGL2Samples/blob/master/samples/texture_3d.html
http://www.realtimerendering.com/blog/webgl-2-new-features/

**** TODO tile-based deferred shading?


use depth range optimize


optimize in webgl2:
https://github.com/tiansijie/Tile_Based_WebGL_DeferredShader:
The WebGL 1.0 is not support reading data form depth buffer. We work around this issue using gl.readPixels. Again, the
WebGL only support UNSIGNED_BYTE, which return a very unaccurate result and enormous reduce the frame rate. 


**** TODO stencil optimize

http://ogldev.atspace.co.uk/www/tutorial37/tutorial37.html











* Record



* TODO unsolved problem
** TODO how to ts compile worker file code?


* TODO need improve



* TODO more
