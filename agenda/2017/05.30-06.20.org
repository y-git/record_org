* 今日计划
** TODO multi thread(v)
use immutable.js

study references:
https://en.wikipedia.org/wiki/Task_parallelism
http://www.dataorienteddesign.com/dodmain/node13.html
https://www.researchgate.net/publication/271271298_Data_Structures_and_Algorithms_for_Data-Parallel_Computing_in_a_Managed_Runtime
https://www.researchgate.net/publication/281740929_Conc-Trees_for_Functional_and_Parallel_Programming

http://bitsquid.blogspot.it/2015/03/multithreaded-gameplay.html


job

terrain geometry process

collision

skin bone matrix compute

cull

shadow build?



command buffer generation(work in offcanvas?):
Dispatch draw calls and state to multiple command buffers in parallel

First class citizen in DX11
 Killer feature for reducing CPU overhead & latency
 ~90% of our rendering dispatch job time is in D3D/driver
1. DX11 deferred device context per core
 Together with dynamic resources (cbuffer/vbuffer) for usage on that
deferred context
2. Renderer has list of all draw calls we want to do for each
rendering “layer” of the frame
3. Split draw calls for each layer into chunks of ~256 and
4. Render to immediate context & execute command lists
5. Profit! 
   

dispatch in parallel to the deferred contexts
 Each chunk generates a command 




*** TODO multi thread render


*** TODO add "action" as one woker thread

*** TODO thread pool
http://www.smartjava.org/content/html5-easily-parallelize-jobs-using-web-workers-and-threadpool
http://stackoverflow.com/questions/13574158/number-of-web-workers-limit
*** TODO SIMD


*** TODO add benchmark(refer to threejs,babylonjs)


* 完成事项
** DONE multi thread render
CLOSED: [2017-06-20 Tue 22:15]
*** DONE implement
CLOSED: [2017-06-02 Fri 17:35]

*** DONE benchmark
CLOSED: [2017-06-05 Mon 18:20]
**** DONE optimize: use SharedArrayBuffer
CLOSED: [2017-06-05 Mon 14:40]
optimize: vMatrix,pMatrix only has one data


**** DONE optimize uniformMatrix4f
CLOSED: [2017-06-05 Mon 15:14]

**** DONE optimize init
CLOSED: [2017-06-05 Mon 18:20]
optimize SharedArrayBuffer?

optimize:
//initShader

postMessage

draw->actual move

**** TODO optimize memory

*** DONE refactor, fix
CLOSED: [2017-06-10 Sat 12:55]
//decouple update rate


//pass vertices,indices(cache them):
//pass compile
//pass run test
//finish dispose
//pass compile
//pass createAndDispose benchmark


//restore indexType

//restore MaterialSystem:
//color
opacity
alphaTest

//fix MaterialSystem->disposeComponent



////optimize createAndDispose benchmark 


*** DONE support no worker version?
CLOSED: [2017-06-11 Sun 13:12]

////WorkerConfig add "notUseWorker" config

//move device/DeviceManagerxxx to renderer/device/

//finish draft

//pass compile

//pass not support run test

refactor:
//move to worker_file, main_file
////rename programxxx,... to ProgramNoWorkerXXX, ...




*** TODO unit test
//pass test

pass createAndDispose benchmark:
//test geometry, material
//dispose arraybuffer,index buffer
//fix transform bug
////test material,geometry default value(set when create)
////set children?

//optimize: buffer min count

//optimize contract test:
implement expect?

//pass other except Material,BasicMaterial:
optimize contract test
optimize: buffer min count





//check max count when create:
check DrawxxxBufferSystem

//test draw









test worker:
//pass Main test(worker, noWorker)
//fix geometry dispose buffer
//test send draw data
//rename: Draw Render Buffer



//fix viewport and unit test


WorkerConfig add "useSingleThread" config

** DONE optimize
CLOSED: [2017-06-20 Tue 15:30]
optimize benchmark with worker



optimize:
////buffer data

test:
////no need to remove hierarchy children?

//fix createAndDispose->color in worker

//optimize createAndDispose in worker

//optimize benchmark with contract test


////give benchmark report

** DONE refactor
CLOSED: [2017-06-20 Tue 22:15]
finish todo

refactor: move renderer->Worker logic to renderer->worker/

extract memoryUtils


** DONE rollup support work
CLOSED: [2017-06-20 Tue 20:31]
//add "rollup renderWorker" to "rollup"


////import worker code to main?
blob
only one rollup config file?

////build worker/no worker package?(refer to bjs)


** DONE publish alpha3
CLOSED: [2017-06-20 Tue 22:15]
pass Wonder.js -> npm install:
//fix:dist/es2015/ should not has src/, node_modules/ !


* 明日计划
** TODO defer render(v)
*** TODO add light
*** TODO add defer render pipeline
*** TODO support switch defer/front pipeline by config data

** TODO run in mobile
*** TODO add mobile render pipeline


** TODO support basic webgl2
*** TODO add webgl2 render pipeline

** TODO refactor: data driven renderer

** TODO publish alpha4

* TODO 未来7日计划
** TODO add clone method

** TODO add Data component





** TODO finish Transform(rotation, translate...)
implement all functions

add more unit

** TODO publish types to definition repo
publish wonder-fantancy-land types
(update wonder.js)

** TODO Wonder.js/wonder-package not post install global packages!
"postinstall": "sudo npm install -g typescript@next && sudo npm install -g rollup && sudo npm install -g typescript-formatter",


** TODO refactor
change Director,GPUDetector to function!

** TODO demo test(in new branch to test)(no unit test,render test)
*** TODO Data driven renderer
rewrite renderer
*** TODO try use webAssembly in engine for cpu compute
**** TODO write a webAssembly demo
use https://github.com/01alchemist/TurboScript to compile js to webAssembly
use webAssembly js api to invoke it in js in demo
*** TODO render rewrite(v)
**** TODO transient Resource System
https://www.slideshare.net/DICEStudio/framegraph-extensible-rendering-architecture-in-frostbite
memory pool for textures



*** TODO finish the way which user can extend by npm/github repo
need use other instead of npm?
(learn http://bitsquid.blogspot.it/2016/01/introducing-stingray-package-manager-spm.html)


*** TODO define schema for editor and hot loading data in editor
The entity-component architecture uses external descriptions for all its components, stored in so-called “Schema” files.
Schemas and their properties/fields are treated completely generically, and hence are used for exposing properties to
the editor. Additionally, schemas have a few more other advantages over serialization- or reflection-based approaches,
which is what I wanted to talk about in a future post. 

refer to:
https://blog.molecular-matters.com/2014/02/21/schema-based-entity-component-data-for-fast-iteration-times/
https://blog.molecular-matters.com/2012/01/31/a-content-pipeline-for-fast-iteration-times/
http://bitsquid.blogspot.com/2016/01/hot-reloadable-javascript-batman.html


refer to:
http://bitsquid.blogspot.com/2010/04/our-tool-architecture.html

*** TODO refactor
refactor getComponent->paradigms



add "compilerOptions" to tsconfig.json(add to base tsconfig.json, others extend it)


mateiral add to meshrenderer


use es5,es6->Object added method to refactor:
use assign instead of extend?

optimize deep clone:
http://stackoverflow.com/questions/122102/what-is-the-most-efficient-way-to-deep-clone-an-object-in-javascript?rq=1
http://stackoverflow.com/questions/728360/how-do-i-correctly-clone-a-javascript-object?rq=1

use keys in Hash->getKeys?


upgrade typescript to 2.2

*** TODO loader,asset data driven
refer to https://blog.molecular-matters.com/2013/05/17/adventures-in-data-oriented-design-part-3b-internal-references/:
 you can still make sure that the scripts themselves are contiguous in memory by allocating them with a suitable
 allocator. As an example, I use a linear/stack-based allocator for all resources being loaded, and resources are sorted
 inside their resource bundles. This means that in memory, all script code (also meshes, textures, etc.) will be right
 next to each other, with pointers to scripts stored elsewhere. 




use string id:
http://cowboyprogramming.com/2007/01/04/practical-hash-ids/
http://www.randygaul.net/2015/12/11/preprocessed-strings-for-asset-ids/

** TODO continue rewrite(keep engine size min)(1.0.0-alpha.xxx)
*** TODO use Data-Driven Design?





Applications in Games
• Particles, Soft-body, Rigid-body, Fluid Simulation
• Collision, Visibility Detection
• Skeletal Animation
• Group Behavior Simulation

http://twvideo01.ubm-us.net/o1/vault/gdcchina14/presentations/833779_MiloYip_ADataOriented_EN.pdf

http://www.slideshare.net/DICEStudio/culling-the-battlefield-data-oriented-design-in-practice



Think about data first, and code second. Class hierarchies aren’t important, but data access patterns are.
Think about how data in your game is accessed, how it is transformed, and what you end up doing with it, e.g. particles, skinned characters, rigid bodies, and tons of other examples.
When there’s one, there’s many. Think in streams of data.
Be aware of the overhead of virtual functions, pointers to functions, and pointers to member functions.



study "virtual function"




**** TODO unity
https://forum.unity3d.com/threads/data-oriented-designed-game-in-unity.350118/

what's Unity DOES?
Unity DOES use DOD, in the places where it eeks out large benefits.

Mesh data and texture data just makes more sense that way. 
*** TODO support multi-thread(maybe need rewrite runtime)
js multi thread:
https://blog.mozilla.org/javascript/2015/02/26/the-path-to-parallel-javascript/
https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer

simd
https://blog.mozilla.org/javascript/2015/03/10/state-of-simd-js-performance-in-firefox/

extract multi thread object/component?


**** TODO multi-thread render
http://www.cnblogs.com/ixnehc/archive/2008/09/04/1284708.html
http://www.bennychen.cn/2011/01/%E5%85%B3%E4%BA%8E%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E6%95%B4%E7%90%86%E5%92%8C%E6%80%9D%E8%80%83/
http://www.cppblog.com/flagship/archive/2009/03/25/77886.html

unity:
https://blogs.unity3d.com/cn/2015/02/06/extending-unity-5-rendering-pipeline-command-buffers/
https://docs.google.com/document/d/1e2jkr_-v5iaZRuHdnMrSv978LuJKYZhsIYnrDkNAuvQ/edit
https://github.com/Unity-Technologies/ScriptableRenderLoop
**** TODO multi-thread load asset



support load multi part of one model?
(refer to http://www.inka3d.com/)
**** TODO multi-thread collision(refer to babylonjs->worker)
*** TODO rewrite render loop(refer to unity)
**** TODO refactor?
refactor: move material to renderer?


add billboard/line renderer?

add skin mesh renderer?
https://docs.unity3d.com/Manual/class-SkinnedMeshRenderer.html

**** TODO support command buffer
https://docs.unity3d.com/Manual/GraphicsCommandBuffers.html
https://docs.unity3d.com/ScriptReference/Rendering.CommandBuffer.html


add more render command(e.g., set render target, ...)

**** TODO support Scriptable Render Loops
https://docs.google.com/document/d/1e2jkr_-v5iaZRuHdnMrSv978LuJKYZhsIYnrDkNAuvQ/edit#
https://github.com/Unity-Technologies/ScriptableRenderLoop

TL;DR
Motivation
Need to perform better on modern hardware
Easier to customize & extend, less “black box”
Easier dealing with backwards compatibility
Scriptable Render Loops: the new foundation
API Overview
Usage, inner workings, performance
New built-in “HD Render Loop”
Lighting Features
Material Features
Camera Features
Workflow / Debug Features
Appendix - Current Rendering Pipeline in Unity
Shadows
Forward Rendering
Deferred Shading
Customization
TL;DR
Reimagine the rendering pipeline to support more flexibility and transparency. The main Unity rendering pipeline will be replaced by multiple "Render Loops", built in C# on a C++ foundation. The C# code for the "Render Loops" will be open-sourced on GitHub, enabling users to investigate, enhance, or create their own custom render loops.
Motivation
Current Unity’s rendering pipeline is described in Appendix - Current Rendering Pipeline. There are several improvements we want to make -- the major ones are spelled below.
Need to perform better on modern hardware
Both “one light per draw call” forward rendering, and “stencil mark + draw shape per light” deferred shading are not exactly modern approaches -- they were fine for roughly DX9 hardware, but with advent of compute shaders generally we can do much better. Our forward shading suffers from too many draw calls (CPU + vertex transform cost) and bandwidth consumed by repeated sampling of surface textures & blending; whereas deferred shading suffers from draw call count, not enough light culling, cost of doing stencil mark + draw call per light and repeated fetching of G-buffer data. Additionally, on tile-based GPUs it does tile store+load too much when realtime shadows are involved, and does not take advantage of tile storage or framebuffer fetch.
We’d like to ship Unity with an out-of-the box rendering pipeline that is targeted at modern hardware -- where we can rely on API & GPU features like compute shaders, draw call instancing, constant buffers etc.
Easier to customize & extend, less “black box”
Most of Unity users would probably not modify the built-in rendering pipeline, but some of the more advanced teams do want to modify or extend it. So it has to be extensible and much less opaque than today.
While the current rendering pipeline is somewhat extensible (users can write their own shaders, manually control camera rendering, change settings, extend the rendering pipeline with command buffers), it is not extensible enough. Additionally, it is too much of a “black box”, and while the documentation, conference presentations, MIT-licensed built-in shader source code and community knowledge does fill in the gaps, some parts are hard to understand without a Unity source code license. We want all the high level code and shader/compute code to be a MIT-licensed open source project, similar to how Post-Processing, UI or Networking already are.
A “single render pipeline for everything” likely has some compromises that make it more flexible at expense of performance. We imagine that, for example, these kinds of rendering pipelines would make sense in many cases:
Optimized for modern PC/console (DX11 baseline, “high end” graphics).
Optimized for on-tile storage of mobile GPUs, using framebuffer fetch or other available techniques.
Optimized for VR (e.g. forward shading + MSAA, single-pass rendering, caching/sharing eye rendering results in distance, various schemes of viewport/resolution stitching).
Optimized for low-end devices (old mobile, old PC) or simple 2D games: simple one pass lighting (limited # of lights, and/or vertex lighting).
These don’t have to be physically separate rendering pipelines, could be options in some other existing pipelines.
Easier dealing with backwards compatibility
This is a hard problem for us at Unity R&D, basically doing big changes to how the rendering engine works is quite hard -- mostly because people do expect to update to a more recent Unity version and have things “still working as they did”. Except when they don’t, i.e. they actively want new changes... For example, we changed Standard shader from Blinn-Phong to GGX specular in Unity 5.3 -- mostly this is a good thing, except for people who were mid-production and now their specular behaves differently (so they probably have to re-tweak their lighting setups and materials).
We’re thinking, that if the high level structure of the rendering code, and all the shader code, was easily “forkable” and versionable, then this problem could become easier.

Scriptable Render Loops: the new foundation
We think all or most of the problems listed above can be solved fairly elegantly by having a solid, orthogonal, performant foundation to build upon, which would basically be “an ability to render sets of objects with various filtering criteria efficiently”. The division of work would be:
Unity C++ code
C#/shader code (MIT open source)
Culling
Render set of objects with filter/sort/params
Internal graphics platform abstraction
Camera setup
Light setup
Shadows setup
Frame render pass structure & logic
Shader/compute code

The C++ side would be mostly not even aware that things like “Camera” or “Light” exist; e.g. culling code gets arrays of bounding primitives and matrices / culling planes as input. It does not care whether it’s culling main view, reflection rendering view or a shadow map view.
Likewise, rendering code is expressed in terms of “from the culling results, render everything that is within opaque render queues range, has this shader pass and does not have that shader pass, sort by material then by distance, setup light probe constants per-object”. There is some amount of conventions and built-in things in there, mostly in what kind of data should be set as per-instance data for each object (light probes, reflection probes, lightmaps, per-object light lists etc.).
There’s a lot of underlying platform graphics abstraction changes that we’re doing in order to be able to provide a robust, high performance and orthogonal set of “building blocks” to build scriptable render loops upon, but they are mostly outside of the scope of this document. Some of the changes worked on are:
Expose “Buffer” as a C# class, that would be used for all kinds of buffer data (vertices, indices, uniforms, compute data etc.). Ability to create and manually update uniform/constant buffers from C# side.
Compute shader related improvements, particularly how data is passed to them.
Remove split between TextureFormat and RenderTextureFormat, have something like “DataFormat” instead that is used in all graphics related code (similar to DXGI formats on D3D). Expose more formats than today.
Asynchronous readbacks of GPU data. Asynchronous compute.

API Overview
Note: the API is in flux, and this document might not be exact wrt whatever Unity version you’re testing with right now.
The main entry point is RenderLoop.renderLoopDelegate, which is in a form of
bool PrepareRenderLoop(Camera[] cameras, RenderLoop outputLoop);
When the render loop delegate is registered, then all rendering goes into that function, and the existing built-in rendering loops are not executed at all.
Inside of the render loop delegate, typically it would do culling for all the cameras (via the new CullResults class), and then do series of calls to RenderLoop.DrawRenderers intermixed with CommandBuffer calls to setup global shader properties, change render targets, dispatch compute shaders etc.
Overall, the design is that the C# render loop code has full control over per-camera logic (it gets all cameras as input), and all per-light logic (it gets all visible lights as a culling result), but generally does not do per-object logic. Objects are rendered in “sets” -- DrawRenderers call that specifies which subset of visible objects to render, how to sort them, and what kind of per-object data to setup.
The simplest possible render loop would look something like this:
public bool Render(Camera[] cameras, RenderLoop renderLoop)
{
  foreach (var camera in cameras)
  {
      // cull a camera
      CullResults cull;
      CullingParameters cullingParams;
      if (!CullResults.GetCullingParameters (camera, out cullingParams))
          continue;
      cull = CullResults.Cull (ref cullingParams, renderLoop);
      renderLoop.SetupCameraProperties (camera);

      // setup render target and clear it
      var cmd = new CommandBuffer();
      cmd.SetRenderTarget(BuiltinRenderTextureType.CameraTarget);
      cmd.ClearRenderTarget(true, true, Color.black);
      renderLoop.ExecuteCommandBuffer(cmd);
      cmd.Dispose();

      // draw all the opaque objects using ForwardBase shader pass
      var settings = new DrawRendererSettings(cull, camera, "ForwardBase");
      settings.sorting.sortOptions = SortOptions.SortByMaterialThenMesh;
      settings.inputFilter.SetQueuesOpaque();
      renderLoop.DrawRenderers(ref settings);

      renderLoop.Submit ();
  }
  return true;
}


Most important new scripting APIs:
// main entry point
struct RenderLoop
{
void ExecuteCommandBuffer (CommandBuffer);
void DrawRenderers (ref DrawRendererSettings);
void DrawShadows (ref DrawShadowsSettings); // similar, slightly specialized
void DrawSkybox (Camera);
static PrepareRenderLoop renderLoopDelegate;
}

// Setup and control how sets of objects are rendered by RenderLoop.DrawRenderers
struct DrawRendererSettings
{
DrawRendererSortSettings sorting;
ShaderPassName shaderPassName;
InputFilter inputFilter;
RendererConfiguration rendererConfiguration;
CullResults cullResults { set };
}

struct DrawRendererSortSettings
{
Matrix4x4 worldToCameraMatrix;
Vector3 cameraPosition;
SortOptions sortOptions;
bool sortOrthographic;
}

enum SortOptions { None, FrontToBack, BackToFront, SortByMaterialThenMesh, ... };

struct InputFilter
{
int renderQueueMin, renderQueueMax;
int layerMask;
};

// what kind of data should be set up per-object when rendering them
[Flags] enum RendererConfiguration
{
None,
PerObjectLightProbe,
PerObjectReflectionProbes,
PerObjectLightProbeProxyVolume,
PerObjectLightmaps,
ProvideLightIndices,
// ...
};

// Culling and cull results
struct CullResults
{
VisibleLight[] visibleLights;
VisibleReflectionProbe[] visibleReflectionProbes;
bool GetCullingParameters(Camera, out CulingParameters);
static CullResults Cull(ref CullingParameters, RenderLoop renderLoop);
// utility functions, like
// ComputeDirectionalShadowMatricesAndCullingPrimitives etc
}


struct CullingParameters
{
int isOrthographic;
LODParameters lodParameters;
Plane cullingPlanes[10];
int cullingPlaneCount;
int cullingMask;
float layerCullDistances[32];
Matrix4x4 cullingMatrix;
Vector3 position;
float shadowDistance;
ReflectionProbeSortOptions reflectionProbeSortOptions;
Camera camera;
}

struct VisibleLight
{
LightType lightType;
Color finalColor;
Rect screenRect;
Matrix4x4 localToWorld;
Matrix4x4 worldToLocal;
float range;
float invCosHalfSpotAngle;
VisibleLightFlags flags;
Light light { get }
}

struct VisibleReflectionProbe; // similar to VisibleLight…

The API outlined above is very much not final! Things that are very likely to change:
Considering an option to not have RenderLoop class, but instead have CommandBuffer contain functions like DrawRenderers etc., and possibly have nested command buffers too.
Culling API changes to enable more performance, i.e. jobified culling overlapping with other work.
Possibly more renderer filtering options.
More explicit “render pass” controls, instead of current “set render target” API.
Usage, inner workings, performance
The general flow is that your own render loop code is responsible for culling, and for rendering everything. Including setting up per-frame or per-renderpass shader uniform variables, managing temporary render targets and setting them up, dispatching compute shaders etc.
Visible lights and probes can be queried from the cull results, and for example their information put into compute shader buffers for tiled light culling. Alternatively, the render loop provides several ways of setting up per-object light lists for DX9-style forward rendering.
On the CPU performance side, the API is built in a way where there’s generally no per-object operations going on -- the C# side of the code is independent of the scene complexity. It typically loops over cameras, and does some iteration over visible lights to either render shadows, or to pack light data for shader usage. The rest of code that is written in C# is setting up render passes / render textures, and issuing “draw this subset of visible objects” commands.
The C++ part of code (culling, DrawRenderers, DrawShadows) is written in a high-performance style that generally just goes over tightly packed data arrays, and is internally multithreaded. Our current experiments show that with this split (high level frame setup in C#, culling/rendering in C++) we can get same or even better performance of our previous rendering loop implementations.
The C# side looks like it would create a lot of garbage-collected objects; we are looking into ways of exposing “native” (C++ side) data directly to C# without extra round-trips; in C# that would look very similar to an array that writes directly into native side memory. This is a somewhat separate topic, which we’ll talk about separately.

New built-in “HD Render Loop”
We plan to provide a built-in “HD Render Loop” targeted at modern (compute-capable) platforms. Currently it is developed with PC and PS4/XB1 consoles in mind, but we’ll be looking at optimizing it for high-end mobile platforms too. Of particular interest for mobile is optimizing it for on-tile storage / framebuffer fetch and other bandwidth-saving techniques.
Internally, shaders are written in a way that is less reliant on separate shader variants for every imaginable knob, and more using “static” (uniform based) branching, with shader variant specializations only used where that makes sense based on shader analysis / profiling on modern GPUs.
The new HDRenderLoop is being developed at github ScriptableRenderLoop (might be messy at any point, only use if you’re super-curious right now).
Lighting Features
Tiled light culling with compute shaders:
Fine pruned tiled lighting (FPTL) for deferred shaded opaque objects.
Clustered tiled lighting for forward-rendered objects and transparencies.
Rendering can be switched between deferred and forward, depending on what is better for the project.
Lights:
Usual punctual (point/spot) and directional lights.
Area lights (polygonal lights and line lights).
Correct linear lighting & PBR.
Physical light units, IES lights.
(Later) Frustum lights (i.e. bounded directional light).
Shadows:
All realtime shadows are suballocated from a single atlas.
Intuitive controls over shadow memory budget and per-light resolution overrides.
Better PCF filtering, particularly for spot/point lights.
Shadows on semitransparent objects.
GI:
Correct HDR.
Consistency with direct illumination.
(Later) Improved Shadows
Exponential shadow maps (ESM/EVSM).
Improved shadows for area lights.
(Later) Volumetric Lighting
Sky/fog atmospheric scattering model.
Local fog.
Material Features
GGX with Metal & Specular parametrizations, similar to current Standard shader.
Anisotropic GGX (Metal parametrization)
Sub-surface scattering & transmission
Clear coat
Double sided support
Good specular occlusion
Layered materials (mix & mask inputs of other materials, with up to 4 layers)
Heightmaps either via parallax or displacement tessellation
(later) Built-in LOD cross-fade / dithering
(later) Hair, Eye, Cloth shading models
Camera Features
Physically based camera parameters
Support for Unity’s PostProcessing stack
Distortion
Velocity buffer (for motion blur / temporal AA)
(later) Half/quarter resolution rendering (e.g. for particles) and compositing.
Workflow / Debug Features
Views of shader inputs (albedo, normals etc.)
Views of all intermediate buffers of rendering (lighting, motion vectors etc.)
Debug menu to control rendering of various passes

Appendix - Current Rendering Pipeline in Unity
Currently (Unity 5.5 and earlier) Unity supports two rendering pipelines for scene (forward rendering and deferred shading), and one way to render realtime shadows. Following is the description of the current pipeline in more detail:
Shadows
Shadowing system mostly works the same no matter whether the forward or deferred shading is used.
Each realtime light with shadows enabled gets a separate shadow map.
Shadow maps are traditional depth texture maps, in shaders sampled with PCF filtering (no VSM/EVSM etc. shadows).
Directional lights can use cascaded shadow maps (2 or 4 cascades); the shadow map space is divided into cascades like in an atlas.
Spot lights always use simple 2D shadowmap; point lights use a cubemap.
Shadowmap size is computed based on quality settings, screen resolution and light’s projection size on screen; or can be controlled by game developer explicitly from scripts per-light.
Cascaded shadow maps are applied in “screen space” -- there’s a separate “gather and do PCF filtering” step that produces screenspace shadow mask texture; later on regular object rendering just does one sample into this texture.
No support for receiving shadows onto semitransparent objects.
Forward Rendering
The default mode of operation is largely DX9-style “one draw call per light with additive blending”. Quality settings of the game determine how many lights per-object will be rendered in realtime; the rest are folded into a spherical harmonics (SH) representation and rendered together with other ambient lighting.
Optionally before main scene rendering: a “depth texture” rendering pass. This kicks in if scripts require it, or other features (e.g. realtime cascaded shadows) need it. Conceptually this is similar to Z-prepass; produces a texture with scene depth buffer.
Optionally before main scene rendering: a “motion vectors” rendering pass. This kicks in if scripts (e.g. motion blur or temporal AA) require it. Renders a texture of velocity vectors for objects that need them.
Realtime shadow maps are rendered before main scene rendering; all shadows are in memory at once.
Actual scene rendering pass specialized in two shader sets: “ForwardBase” (ambient/probes + lightmaps + lighting/shadows from main directional light), followed by additive blending “ForwardAdd”, that does realtime lighting one light at a time.
Deferred Shading
This is “traditional” DX9-style deferred shading: G-buffer rendering pass, followed by “render light shapes one by one” pass where each of them reads G-buffer data, computes illumination and adds it into lighting buffer.
Similar to forward rendering, an optional motion vectors pass before the G-buffer.
Reflection probes are rendered one by one similar to lights, by rendering box shapes and adding reflections into a texture.
Lights are rendered one by one, by rendering light shapes (fullscreen quad or sphere or cone) and adding reflections into a texture.
Shadow map for a light is rendered just before rendering each light, and generally discarded right after done with it.
Stencil marking is used for both lights and reflection probes to limit the amount of pixels actually computed.
Objects that don’t support deferred shading, and all semitransparent objects, are rendered using forward rendering.
Customization
It is possible to customize the above behavior to some extent, but not much. For example, Valve’s The Lab Renderer (on Asset Store) replaces the built-in behavior by (purely in C# + shaders):
Implementing a custom shadows system, where all shadows are packed into one atlas.
Custom forward rendering system, where all lights are rendered in one pass; light information is setup into custom shader uniform variables.
**** TODO support render component?(refer to Scriptable Render Loop design!)
(upgrade render command to render component?)
so now has two type component:
logic component
render component


regard different render loop as different render object
(mobile,webgl1 pc,webgl2 pc)
(forward render, defer render)

so now has two type object:
logic object
render object




so now has two type script component user can control:
logic script component
render script component(replace command buffer design?)



move buffer,bufferContainer logic to component?
(e.g. so can move animation,shadow logic all to component?)
or buffer,bufferContainer can be extensible by user?


solve:
communication between:
logic object and render object
logic component and render component


*** TODO add unit test

*** TODO enhance render test

ci can run render test

can generate correct image in the debug page of render


use headless-gl + jest + ci to test!!!???



**** TODO solve "render test not pass in outer screen" problem

**** TODO move render test to npm/submodule
move more samples there


add README.org:
todo: add compare in two way:
- overlap yours and correct img
- get diff pixel img

**** TODO add render test

*** TODO add benchmark auto test
build basic test scenes

compare with time

*** TODO solve how to extend by user:(refer to unity)


how to write own component
how to write own extension(material)
build component repository?


**** TODO extend script
user can write local script component

**** TODO extend material

**** TODO extend glsl

***** TODO glsl use require,include?
@bhouston what about a custom webpack loader for the glsl files instead of using the raw-loader? The loader could take care of recursively resolving any #include lines in the root shader file. Any shader could be required in with e.g.:

var vert = require('three-glsl!../shaders/my-shader.vert')
var frag = require('three-glsl!../shaders/my-shader.frag')
just a thought

**** TODO extend component
user can write local/public component

add wonder_component_config.json, add "components" field.
e.g.
{
components:[
"wonder-component-aaa"
]
}

wonder should read this field and register it


public component:
(refer to typescript->d.ts)
user should send it to public github repository
in ci, it will check and run unit test

after pass ci and merge it, it will be published to @wonder-components/xxx npm package 




*** TODO study how to separete low-level(optimized) and high-level(extensible) parts
refer to unity:
low-level:c++   high performance, multi thread
high-level:c#   extensible

*** TODO study script(integrate with engine?)
*** TODO move event manager to be npm package
*** TODO build simple world editor(v)


*** TODO optimize sort render command(WebglRenderer.ts)
use radix sort?

refer to:
https://www.byvoid.com/zhs/blog/sort-radix
http://www.dataorienteddesign.com/dodmain/node10.html


use web worker to parallel sort:
It is possible to make this last stage of the process parallel by having each sorter ignore any values that it reads
that are outside its working set, meaning that each worker reads through the entire set of values gathering for their
bucket, but there is still a small chance of non-linear performance due to having to write to nearby memory on different
threads. During the time the worker collects the elements for its bucket, it could be generating the counts for the next
radix in the sequence, only requiring a summing before use in the next pass of the data, mitigating the cost of
iterating over the whole set with every worker. 

If your data is not simple enough to radix sort, you might be better off using a merge sort or a quick sort, but there
are other sorts that work very well if you know the length of your sortable buffer at compile time, such as sorting
networks. Through merge-sort is not itself a concurrent algorithm, the many early merges can be run in parallel, only
the final merge is serial, and with a quick pre-parse of the to-be-merged data, you can finalise with two threads rather
than one by starting from both ends (you need to make sure that the mergers don't run out of data). Though quick sort is
not a concurrent algorithm each of the sub stages can be run in parallel. These algorithms are inherently serial, but
can be turned into partially parallelisable algorithms with O(log n) latency. 



Multi-threaded sorting: Each command bucket can be sorted independently, in parallel.





*** TODO add collision(v) 
**** TODO multi thread
***** TODO add benchmark(refer to threejs,babylonjs)

*** TODO webgl2(v)

*** TODO add load asset(v)
**** TODO add AssetDatabase to support aync load asset
(move out to be a project in wonder group?)
*** TODO add cpu particle system(v)
*** TODO add hdr post effect(v)(move to extension)
**** TODO design
refer to unity post process stack:
https://forum.unity3d.com/threads/new-post-processing-stack-pre-release.435581/
https://github.com/Unity-Technologies/PostProcessing/wiki
https://www.reddit.com/r/Unity3D/comments/56r2h6/unity_technologies_postprocessing_stack_image/

refer to babylonjs

*** TODO support webp image format
https://isux.tencent.com/introduction-of-webp.html


** TODO fix bug(refer to mine/Wonder.js->commits)
//UIRenderer support set canvas size(left,top,width,height)


//fix OBJ converter->ObjectsConverter:
refer to threejs->OBJMTLLoader.js
use 0419.obj model
(children should be 448, but mine is 300+!)
(the g group is wrong! maybe all should rewrite!)



//model info

//model color

optimize picking:
compute center point, closest to camera

////show house:
double side?

use basic material?


//flag a,b,c


need add mesh collider

** TODO update .gltf(.wd) to 2.0

** TODO advanced multi-thread
*** TODO multi thread logic
**** TODO add action
**** TODO add collision

*** TODO SIMD



*** TODO task system
main threads(update thread, render thread)
worker threads:worker_thread_count = number_of_cores - main_thread_count


work items



sub task?


task manager

one depend?

priority



open list(not completed job) + need perform list

**** TODO optimize create render command
preallocate 10000 render commands in array

multi thread create render command

**** TODO define render data in config file

*** TODO thread pool
http://www.smartjava.org/content/html5-easily-parallelize-jobs-using-web-workers-and-threadpool
http://stackoverflow.com/questions/13574158/number-of-web-workers-limit
** TODO use optimize-js to package
https://github.com/nolanlawson/optimize-js


////***** TODO add package unit tests
** TODO optimize shaders
https://www.zhihu.com/question/22595954/answer/61277904
study:
tag math+visibility组件
shader cache收集系统


Windows performance toolkit




only iterate shader lib once



看来是根据序号得到顶点变量名
这个处理的好，这样通过查询来获得变量名，就不要先保存这些变量名了:
refer to three:
function fetchAttributeLocations( gl, program, identifiers ) {

		var attributes = {};

		var n = gl.getProgramParameter( program, gl.ACTIVE_ATTRIBUTES );

		for ( var i = 0; i < n; i ++ ) {

			var info = gl.getActiveAttrib( program, i );
			var name = info.name;

			// console.log("THREE.WebGLProgram: ACTIVE VERTEX ATTRIBUTE:", name, i );

			attributes[ name ] = gl.getAttribLocation( program, name );

		}

		return attributes;

	}


function WebGLUniforms( gl, program, renderer ) {

	UniformContainer.call( this );

	this.renderer = renderer;

	var n = gl.getProgramParameter( program, gl.ACTIVE_UNIFORMS );

	for ( var i = 0; i < n; ++ i ) {

		var info = gl.getActiveUniform( program, i ),
			path = info.name,
			addr = gl.getUniformLocation( program, path );

		parseUniform( info, addr, this );

	}

}



** TODO skin optimize
*** TODO use blender to build skin animation


fix yuan bao problem:
the animation and the static model's rotation is not the same!(animation has rotate(0,-90,0)!)
(
gltf is correct(monster is correct)(by compare with threejs)

but fbx is wrong!(xsi_man_skinning.fbx)(compare with threejs->webgl_loader_fbx.html)
maybe the bind shape matrix is wrong? need parse!?
# parse bind shape matrix:
# http://www.gamedev.net/topic/574309-solved-fbx-animation-problems/
# refer to babylonjs->SkinInfo.cpp->bindPoses ?)




*** TODO support multi animations in one fbx
pass fbx->converter->multi skin animations!:
use blender to add multi animations of one model in one .fbx file
learn how to separate and combine character and its props animations!


*** TODO optimize skin
fbx:
  parse bind shape matrix:
  http://www.gamedev.net/topic/574309-solved-fbx-animation-problems/
  refer to babylonjs->SkinInfo.cpp->bindPoses ?




optimize: 
not update tranlation,scale(pre handle key frame data)



write to texture:
judge vertex texture


//add basic optimize


add render test


optimize: 
//if bindShapeMatrix is identify, set it null and not multiply

other "todo" optimizes


optimize:
query max uniform data arr count



compute in gpu
1) Make sure that the size of the bones array is correct. Often times, you will find that part of the mesh is skinned fine while the other parts are not skinned correctly. If so make sure the size of the bones array is correct.  

There are two things that you have to be careful about.





*** TODO publish





** TODO fbx support morph anim

*** TODO pass skin + morph(use blender)

*** TODO publish


** TODO support animation blend

*** TODO publish

** TODO support animation control(using action to control)
refer to unity:
https://docs.unity3d.com/Manual/AnimationSection.html



support time limit logic(e.g. isTimeExceed5000)

support frame control

*** TODO refactor:extract AnimationEngine and move out to be a new project

*** TODO publish


** TODO finish phone->todo
*** TODO use compress texture?

support .pvr in ios

**** TODO use blender to generate compress texture

*** TODO audio add more control(play one time, stop...)


*** TODO publish 
** TODO optimize(beta)
*** TODO read references
https://developer.nvidia.com/nvidia-gpu-programming-guide

http://www.cnblogs.com/ghl_carmack/p/4107042.html


*** TODO cpu optimize
optimize clone,extend,deepextend:
https://cnodejs.org/topic/56c49662db16d3343df34b13
use Object.assign()
https://github.com/Microsoft/TypeScript/issues/3429
( typescript2.2->extend)
https://github.com/Microsoft/TypeScript/pull/13604






optimize transform:
optimize Transform->state?

check is the same in setting position,scale,rotation, localXXX(new value === old value, not set,dirty?)



optimize shader:
staticly compile shader param of libs to one large collection of the one entityObject
(so no need to iterate the shader libs at runtime)


*** TODO memory optimize
add global Temp class, for save temp matrix,vector...
(refer to bjs->math.ts->Temp class)

use memory pool instead of Temp class?
(refer to sk_design->MemoryUtil,MemoryPool)



show memory info:
refer to sk_design->WebGLRenderer->dump method


optimize Vector2/3/4:
remove "values" attr


optimize hash->removeChild



memory optimize:
https://www.scirra.com/blog/76/how-to-write-low-garbage-real-time-javascript
http://blog.tojicode.com/2012/03/javascript-memory-optimization-and.html

http://www.cocos2d-x.org/wiki/How_to_Optimise_Memory_Usage
http://www.cocos2d-x.org/wiki/Memory_Management_of_JSB

http://stackoverflow.com/questions/13914959/three-js-memory-management


http://www.html5gamedevs.com/topic/6903-memory-consumption-difference-between-111-and-112-beta/




use instance pool to re-use render commands

*** TODO specific optimize
**** TODO octree optimize
**** TODO instance optimize
////**** TODO shadow optimize

*** TODO optimize skeleton animation
把所有不同的角色的骨骼相关的矩阵和变换信息写入到纹理里(refer to playcanvas, threejs)
(fallback:if not support vertex texture, pass uniform data instead)
http://ftp.opengpu.org/forum.php?mod=viewthread&tid=18164&extra=page%3D1

http://http.developer.nvidia.com/GPUGems3/gpugems3_ch02.html

https://github.com/mrdoob/three.js/issues/3187


use Skinned Instancing

use quaternion for rotate skeleton



*** TODO more?


** TODO finish projects to apply engine(beta)
(add needed feature from 0.x engine version!!!)

*** TODO in pc
**** TODO write a rpg game(spirit game)(spirit dream?)(can get resource about 3d engine, meditation, spirit, pi gu, juexing...)
refer to https://github.com/pissang/qtek-bootcamp 

use blender to generate assets


**** TODO build custom outer scene(octree+lod+direction light+collision+shadowmap+terrain+water(mirror reflection, refraction) + morph animation player character)
***** TODO support physics heightmap
add physics box,sphere
player can collision with these box,sphere







add demo:
refer to babylonjs->Samples/Scenes/WorldMonger/

refer to http://www.babylonjs-playground.com/#E6OZX#7
add mix map, normal map

layer texture(blend)(use blend map)

water

cloud

sky dome


add tree

add grass

shadow(shadowMap, lightMap)




**** TODO build custom room scene(point light+lightmap+shadowmap+cubemap reflection+articulated camera+collision)





*** TODO in mobile
**** TODO run in mobile
***** TODO rewrite bainian project(use require:cmd/nodejs)
****** TODO fix in mobile
run in mobile environment:
fix skin animation:(first animation is not play completely)
(due to elapsed !== _beginElapsedxxx at the first update!)
refactor and test: save begin time
articulated also has the bug!?


build mobile test environment



fix:
set pixel ratio in mobile -> set style width/height?
         view.width = view.width * window.devicePixelRatio;
         view.height = view.height * window.devicePixelRatio;
         view.styleWidth = view.width + "px";
         view.styleHeight = view.height + "px";

set viewport?:
gl && gl.viewport(
    camera.viewPort[0] / window.devicePixelRatio,
    camera.viewPort[1] / window.devicePixelRatio,
    camera.viewPort[2] / window.devicePixelRatio,
    camera.viewPort[3] / window.devicePixelRatio
);



optimize:
hongbao-> parse and assemble geometry is slow
(compress position,joint,weight... to one buffer)





fix:
maoke->arcball camera->roll up/down is wrong!

unify Animation,SingleLayerKeyFrameAnimation,MultiLayerKeyFrameAnimation->play->params
refactor Animation,SingleLayerKeyFrameAnimation,MultiLayerKeyFrameAnimation->playOneTime(move to Animation)


optimize:
maoke->arcball camera->roll is very slow!




enhance mobile debug:
rewrite console:
http://eclipsesource.com/blogs/2012/08/14/debugging-javascript-on-android-and-ios/
use vconsole:
https://www.qianduan.net/vconsole-open-source/

show profile info



feat: Collider add "setFromVertices"
















optimize:
//solve switch cat slow:
//precompute cat2 bone matrix(update(0)?)


//play sound after show 






















**** TODO mobile optimize
http://www.cnblogs.com/ghl_carmack/p/5401906.html
http://www.cnblogs.com/gameknife/p/3515714.html

https://developers.google.com/speed/docs/insights/mobile

***** refer to hongbao:
optimize:
show other model in later(show bainian animation of another model when click on first model)

optimize:
parse and assemble hilo3d(now parse geometry is very slow)



optimize hongbao in ios(also in android?):
optimize model->antialias in android,ios




optimize hongbao->03b -> cat(xxxSurface_251(66?))->normal compute:
isn't correct!


**** TODO optimize asset
refer to hongbao:
optimize skin animation
optimize model geometry


**** TODO tao fu wa
**** TODO simple room scene(player with skin animation to navigator)
**** TODO simple outer scene





*** TODO in both
**** TODO car demo(replace material)
**** TODO physics demo(like tao fu wa)
**** TODO jiao's picture demo(particle, picking, hdr, reflection)


*** TODO fix problems
*** TODO optimize

** TODO publish v1.0.0
(may not contain all feature of v0.x version!)

*** TODO pass run in windows->ie11
fix:
instance_xxx_shadow_xxx
merge_model




*** TODO other



increase runtime test rate from 92% to 95%


can work from the scratch
(runtime, package, test, converter, height generater)
(commonLib, frp)


add wonderjs website

add wonderjs blog

add wonderjs forum

add wonderjs online demo


write document, tutorials:



support full screen(refer to babylon.engine.ts->450 line)


** TODO optimize cpu(v0.5.8)
//render target renderer(e.g. Mirror,Refraction,DynamicCubemap, ...) and procedural renderer, shadowMap(refer to
babylonjs->Samples/Demos/Instances/instances.js line 100), VideoTexture,   add "refreshRate", "refresh control"(like
stop refresh,start refresh, refresh(count):refresh the specify times
(Math.ceil, 1->refresh every frame; 2->refresh every 2 frames;0->refresh only in the first frame, ...)
(add refresh rate counter)





use texture matrix to replace repeat,part data



move BoxGeometry, ...(except ModelGeometry,CustomGeometry) computation
to worker
(refer to <<webgl insights>> p81)





optimize math library(e.g., Matrix4,Matrix3...):
use TDL, Closure, and gl-matrix instead? or modify the existed library
based on them?

From the benchmark it is clear that TDL, Closure, and gl-matrix are
the top contenders in terms of performance as tested on a MacBook Pro
(OS X 10.9.5, 2.4 GHz Intel Core i7, 8 GB 1333 MHz DDR3).  





//data orient driven(refer to game engine germ 1/2)



regard octree,lod as benchmark test



https://blogs.msdn.microsoft.com/eternalcoding/2013/05/21/benchmarking-a-html5-game-html5-potatoes-gaming-bench/
https://blogs.msdn.microsoft.com/eternalcoding/2015/01/07/javascript-shoud-i-have-to-cache-my-arrays-length/
https://blogs.msdn.microsoft.com/eternalcoding/2015/02/02/using-user-mark-to-analyze-performance-of-your-javascript-code/




https://www.smashingmagazine.com/2012/11/writing-fast-memory-efficient-javascript/
https://msdn.microsoft.com/en-us/library/windows/apps/hh781219.aspx
https://channel9.msdn.com/Events/Build/2013/4-313
http://malideveloper.arm.com/downloads/GDC14/Thursday/10.30amWebGL.pdf




use webgl-inspector->highlights to see duplicate setting uniforms

Note that uniforms are specific to programs and they are remembered by the programs, so you don't have to re-set them
every time you switch programs! 




not create duplicate textures







BufferContainer->getChild->apply:
remove @cache
use {} instead of Hash



optimize ArticulateAnimation->_updateTargets





ActionManager->update
script->update





optimize benchmark_shadow test:
optimize memory
camera vpMatrix add cache






optimize instance with octree,lod

optimize:
show 10000 spheres with 60fps(instance)
show 20000 spheres with 60fps(instance + lod)
show 40000 spheres with 60fps(instance + octree)
show 60000 spheres with 60fps(instance + octree + lod)

////only render visable instance

////if not support instance, optimize ethier
(refer to bjs(babylonjs))

////*** TODO optimize: cache all uniform/attribute position when init(then look up the cache table to get the position when send glsl data)
////refer to babylonjs->effect.ts, engine.ts->getUniforms/getAttributes method








support merge instancing?
http://www.humus.name/Articles/Persson_GraphicsGemsForGames.pdf
http://hacksoflife.blogspot.com/2013/01/instancing-for-bricksmith.html

When reducing the number of draw calls there are two standard approaches. Multiple
instances of a single mesh is typically done with regular instancing. If there are multiple
meshes, but a single instance of each, they can be merged into a single vertex and index
buffer and drawn with a single draw call. However, sometimes you want to draw multiple
meshes, with multiple instances of each, and each with their own transforms or other instance
data. With instancing this results in multiple draw calls. With the standard merging approach
you need to duplicate the vertex data.
We came up with an approach that combine the benefits of merging and instancing such that
you can draw it all with a single draw call without duplicating vertex data. Thus, for the lack of a
better name, it can be referred to as Merge-Instancing.














optimize octree sample: frustum(especially arcball camera), ray picking, collision

bug:
if add/remove EntityObject, will the octree rebuild?




optimize water,terrain



optimize mirrorMirror, dynamicCubemapTexture




optimize lod

reduce composite layers time(when move camera to switch geometry in lod sample):
http://www.chromium.org/developers/design-documents/gpu-accelerated-compositing-in-chrome
http://www.html5rocks.com/en/tutorials/speed/scrolling/
https://developer.chrome.com/devtools/docs/timeline
http://www.html5rocks.com/zh/tutorials/speed/layers/



optimize collision:
add layers:
http://docs.unity3d.com/Manual/LayerBasedCollision.html








optimize shadow(especially point shadow)
bug: 
in collision_box sample, why shadow break when move box down to near the edge of screen?(not caused by light->shadowCameraXXX)

test light move



not bind color to frame when build shadow map?

not bind and send uniform when build shadow map





optimize:
cache camera->vpMatrix
shadow layer

////not bind texture when build shadow map










*** TODO other

//if the texture is the same there is NO rebinding:

https://github.com/BabylonJS/Babylon.js/blob/master/Babylon/babylon.engine.ts#L1961



//move "create program" logic out of shader?



**** TODO optimize refer to <<OpenGL Insights>>  39 chapter

Group objects in buffers based on data format (type and layout) and update
frequency.

Ensure that appropriate buffer usage flags are used.

Use static buffers and fully specify the contents of buffers before draw time.


Use immutable textures when available?
If EXT texture storage is not supported, ensure that a complete texture is
created and consistently defined. 


Avoid redefining the format or size of existing textures, and create a new tex- ture instead. 


Use packed depth-stencil for combined depth and stencil support.

Avoid masked clear operations.

Avoid using complex conditional statements and loops with a high maximum number of iterations in shaders. 



**** TODO z prepass

not bind and send uniform when z prepass
(bindless or uniform blocks are ways of minimizing these)






***** TODO WebGLRenderer: sort opaque objects from front to end

On IMR GPUs, this extra bandwidth consumption and fragment work can be limited by sorting and rendering geometry from
front to back (see Figure 24.4).  

An additional heuristic for games is to render the player character first and the sky-box last  









**** TODO update profiling tool
refer to <<OpenGL Insights>> 36 chapter

Intel Graphics Performance Analyzers (GPA):(can use only in windows?)
http://www.intel.com/software/gpa

WebGL Inspector shows the WebGL side, and Frame Analyzer shows the post-translation DirectX equivalent 

start Intel Graphics Performance Analyzers:
Fortunately, starting Chrome with a --no-sandbox flag allows GPA to at- tach to the correct rendering process and
trigger frame captures.  





use [[https://software.intel.com/en-us/gpa/details][Graphics Performance Analyzers]] ?


**** TODO use Map/Set to update Hash/Collection



** TODO optimize memory, cg(v0.5.9)




vertex compress
https://cesiumjs.org/2015/05/18/Vertex-Compression/
compress billboard instance data:
https://cesiumjs.org/2015/10/28/Billboard-Instancing/





optimize benchmark_2000_boxes_forRunTest(add action component)




This kind of unwanted memory churn is usually created by algorithms
that compute intermediate values that are quickly thrown away. 

Listing 4.7 A memory-inefficient linear interpolation function.
Cartesian3.add = function(left, right) { var x = left.x + right.x;
var y = left.y + right.y;
var z = left.z + right.z;
return new Cartesian3(x, y, z); };
Cartesian3.multiplyByScalar = function(value, scalar) {
var x = value.x * scalar;
var y = value.y * scalar;
var z = value.z * scalar;
return new Cartesian3(x, y, z); };
Cartesian3.lerp = function(start, end, t) {
var tmp = Cartesian3.multiplyByScalar(end, t);
var tmp2 = Cartesian3.multiplyByScalar(start, 1.0 - t); return Cartesian3.add(tmp, tmp2);
};


Every call to lerp allocates three objects: two intermediate
Cartesian3 instances and the result instance. While a microbenchmark
of 100,000 calls takes about 9.0 milliseconds in Firefox, it doesn’t
expose a problem with garbage collection because the memory is not
cleaned up until after our benchmark has already completed. 
We can remove the extra memory allocation by using two simple
techniques. First, we require users to pass in an already allocated
result parameter to avoid having to create a new instance every
time. Second, we use module-scoped scratch parameters in calls to add
within lerp. 

Listing 4.8 Memory-efficient linear interpolation using result parameters and scratch variables.
Cartesian3.add = function(left, right, result) {
 result.x = left.x + right.x;
result.y = left.y + right.y;
result.z = left.z + right.z;
return result; };
Cartesian3.multiplyByScalar = function(value, scalar) {
 result.x = value.x * scalar;
result.y = value.y * scalar;
result.z = value.z * scalar;
return result; };
var tmp = new Cartesian3(0, 0, 0); var tmp2 = new Cartesian3(0, 0, 0);
Cartesian3.lerp = function(start, end, t, result) { Cartesian3.multiplyByScalar(end, t, tmp); Cartesian3.multiplyByScalar(start, 1.0 - t, tmp2); return Cartesian3.add(tmp, tmp2, result);
};




clean memory
http://stackoverflow.com/questions/23598471/how-do-i-clean-up-and-unload-a-webgl-canvas-context-from-gpu-after-use





For performance, avoid object allocation in the render loop. Reuse objects and arrays where possible, and avoid built-in
array methods such as map and filter. Each new object creates more work for the Garbage Collector, and in some cases, GC
pauses can freeze an application for multiple frames every few seconds. 






release when need:
manage ProgramTable,BufferTable:
add references count
check references to decide whether to dispose the one whose referencs is 0


https://blogs.msdn.microsoft.com/eternalcoding/2013/09/04/reducing-the-pressure-on-the-garbage-collector-by-using-the-f12-developer-bar-of-internet-explorer-11/


http://goocreate.com/learn/reducing-memory-usage/
https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management
http://www.html5rocks.com/en/tutorials/speed/static-mem-pools/


use Array instead of Collection in the key path?

memory allocate
http://www.mystengine.com/blog/?p=59
http://www.cnblogs.com/dreams/archive/2007/03/25/687310.html





** TODO optimize gpu

*** TODO optimize glsl
https://www.opengl.org/wiki/GLSL_Optimizations


[[http://aras-p.info/blog/2011/08/17/fast-mobile-shaders-or-i-did-a-talk-at-siggraph/][Fast Mobile Shaders]]


When we suspect that our application is shader-bound, we can always
perform a simple test to see if this really is the case: Replace all
of the shaders with trivial ones that only render a single
recognizable color and measure the performance. If the performance is
significantly changed, the application is likely shader-bound—either
by GPU computa- tion or by texture fetches performed by the shaders. 




*** TODO other

http://malideveloper.arm.com/downloads/GDC14/Thursday/10.30amWebGL.pdf



////** TODO optimize: batch draw calls(v0.5.10)
use stride in gl.vertexAttribPointer(refer to Wozlla Engine)




render to target support mipmaps(refer to bjs)
*** TODO Vertex cache optimization 
refer to <<OpenGL InSights>> 26 chapter: Indexing Multiple Vertex Arrays
This chapter shows a simple solution to convert nonindexed data into an indexed form, allowing its use in an efficient
way with many file formats such as OBJ, X, VRML, and COLLADA. 

refactor obj,md2 indices build?



A number of algorithms can be found in the literature for reorganizing the indices in order to get a better
post-transform cache usage. 
In particular, I recom- mend nvTriStrip, which is slow but ready-to-use, and Tom Forsyth’s
algo- rithm [Forsyth 06], which runs in linear time. 

https://www.opengl.org/discussion_boards/showthread.php/167481-Vertex-cache-optimization

http://tomforsyth1000.github.io/papers/fast_vert_cache_opt.html

https://github.com/vivkin/forsyth
http://www.cnblogs.com/ghl_carmack/p/4107042.html


*** DONE VAO

webgl 2? just use extension in webgl 1!
To save a lot of API calls, use vertex array objects (VAOs) or interleave static vertex data. 




that can significantly improve per- formance on mobile devices

VAOs are available in WebGL 1.0 with the OES_ vertex_array_object
extension, which is widely supported on mobile devices. As of early
2015, more than 80% of smartphone and tablet clients recorded by
WebGL Stats have it 



If vertex array objects (VAOs) are supported, then we build one for
each combination of vertex buffers and index buffer present in the
DrawParameters objects. As we share the buffers between many different
geometries, the actual number of combinations is usually quite
low. This allows us at dispatch time to simplify all the buffer checks
to a single equality comparison between the current VAO and the
previous one. Even when the VAOs are dif- ferent, setting them with
WebGL is cheaper on the CPU than setting all the different buffers and
vertex pointer attributes, which makes them a big win for complex
scenes.


Adding a fallback for devices without VAO support is also
straightforward. Let’s call the code that binds buffers and sets
vertex attrib pointers related to a specific mesh the binding
block. If VAOs are supported, the code should initialize the VAO of
each mesh using the binding block. Then, when the mesh is drawn, the
code either binds the VAO if VAOs are supported, or executes the
binding block if VAOs are not supported. The only case where this
becomes more complicated is when there’s a different number of active
vertex attribute arrays for different meshes—then the code should add
disable- VertexAttribArray calls where appropriate. For a complete
code example, see an explanation of VAOs* or an implementation of a
fallback path in SceneJS
(https://github.com/xeolabs/scenejs/blob/v4.0/src/core/display/chunks/geometryChunk.js)




Lowering the number of vertex buffers helps to reduce CPU usage if
VAOs are not a good fit for the code for some reason. This can be done
by interleaving different types of vertex data for the same object: If
we have, for example, positions, texture coordinates, and normals for
each vertex, they can all be stored in the same vertex buffer in an
interleaved fashion. In our CPU-bound drawing test that uses four
vertex attributes, interleaving the attributes increased the FPS
around 4%. The downside is that interleaving the data needs to be
either handled by the content creation pipeline or done at load time;
the latter may marginally slow down loading. Interleaving three
attributes for a million vertices in a tight JS loop had a cost of
around 200 ms on a Nexus 5 (2013 phone). 




http://blog.tojicode.com/2012/10/oesvertexarrayobject-extension.html

http://www.openglsuperbible.com/2013/12/09/vertex-array-performance/

 

*** TODO optimize from <<WebGL Insights>>

For portability, space requirements of varyings and uniforms within the limits of the GLSL ES spec. Consider using
vec4 variables instead of float arrays, as they potentially allow for tighter packing. See A.7 in the GLSL ES spec. 










When using an RGB framebuffer, always implement a fallback to RGBA for when RGB is not supported. Use
gl.checkFramebufferStatus. 




If shrinking the browser window results in massive speed gains, consider using a half-resolution framebuffer during
mouse interaction. 



Use OES_element_index_uint to draw large indexed models with a single draw call.



need change???
The textureProj GLSL function, vec4 color = textureProj(sampler, uv.xyw);, can be simulated with vec4 color =
texture(sampler, uv.xy/uv.w) 



**** TODO ANGLE optimize(refer to <<WebGL Insights>>->chapter 1):
- Avoid use of gl.TRIANGLE_FAN, as it may be emulated in software.

- Create new textures, rather than changing the dimensions or format of old ones.
  - if only the pixel data contained in a texture need to be updated, it is best to reuse the texture—the additional
overhead is only incurred when updat- ing texture format or dimensions, because these require redefinition of the mip-
map chain. 

- Do Not Perform Clears with Scissors or Masks(color mask,stencil mask) Enabled
so check and warn info when clear

- Avoid Render Wide Lines as Polygons
(ANGLE does not support line widths greater than 1.0, commonly called “wide” lines)




- Avoid Uint8Array Data in Index Buffers


- Avoid 0xFFFF in 16-Bit Index Buffers
  

- Always Specify the Fragment Shader Float Precision

- Do Not Use Rendering Feedback Loops
(In the OpenGL APIs, attempting to write to and sample from the same texture or renderbuffer in a rendering operation is
considered a rendering feedback loop)


- Don’t Use Extensions without Having a Fallback Path

- Use Immutable Textures When Available (use EXT_texture_storage extension to use texStorage* command instead of
  texImage* command)
Historically, OpenGL and WebGL textures had to be created one mip level at a time. OpenGL does this via glTexImage*, a
method that allows users to cre- ate internally inconsistent textures, considered by the GL to be “incomplete.” This
same method is what is available to developers in WebGL, as texImage*. By contrast, Direct3D requires that users define
the dimensions and format of their entire textures at texture creation time, and it enforces internal consistency. 

Because of this difference, ANGLE must do a considerable amount of bookkeep- ing and maintain system memory copies of
all texture data. The ability to define an entire texture at creation time did later get introduced to OpenGL and its
related APIs as immutable textures, which also enforce internal consistency and disallow changes to dimensions and
format. Immutable textures came to OpenGL ES 2.0 with EXT_texture_storage [Khronos 13a], and they are included in the
core OpenGL ES 3.0 specification and the WebGL 2 Editor’s Draft specifica- tion. When immutable textures are available
via extension or core specification, some of ANGLE’s bookkeeping can be avoided by using the texStorage* com- mands to
define textures. 


- Use RED Textures instead of LUMINANCE(use EXT_texture_rg extension [Khronos 11] to use the RED and RG formats)
(simply using RED textures in place of LUMINANCE and RG in place of LUMINANCE_ALPHA when using ANGLE with APIs that
support them) 

In WebGL and unextended OpenGL ES 2.0, the only option developers have for expressing single-channel textures is the
LUMINANCE format, and LUMINANCE_ALPHA for two-channel textures. The EXT_texture_rg extension [Khronos 11] adds the RED
and RG formats, and these formats become core functionality in OpenGL ES 3.0. The formats also appear in the WebGL 2
Editor’s Draft specification. Meanwhile, Direct3D 11 has dropped all support for luminance textures, providing only red
and red-green formats [MSDN 14a]. This may seem to be a trivial difference—a channel is a channel—but sampling from a
luminance texture is performed differently than from textures of other formats. The single channel of a luminance
texture is duplicated into the red, green, and blue channels when a sample is performed, while sampling from a RED
texture populates only the red channel with data. Similarly, the second channel of a LUMINANCE_ALPHA and an RG texture
will populate only the alpha and green channels in a sample, respectively. To support luminance formats against Direct3D
11, rather than alter the swizzle behavior in shaders, ANGLE instead expands the texture data to four channels. This
expansion, and the associ- ated additional memory and texture upload performance costs, can be avoided by developers
keen for clock cycles by simply using RED textures in place of LUMINANCE and RG in place of LUMINANCE_ALPHA when using
ANGLE with APIs that support them. 



- Avoid Full-Texture Swizzle
Texture swizzling is an OpenGL ES 3.0 feature which allows a texture’s compo- nents to be sampled in a different order,
using the TEXTURE_SWIZZLE_R, TEXTURE_SWIZZLE_G, TEXTURE_SWIZZLE_B, and TEXTURE_ SWIZZLE_A texture parameters. This is
most often used to read RGBA textures as BGRA, or vice versa, and can also be used to replicate components as with
luminance textures. This feature is, however, not supported by Direct3D 11. Even though it appears a seemingly simple
operation to perform during the shader translation, it is actually not feasible to determine which textures are sampled
where, because samplers can be passed from function to function as parameters, and the same texture sampling function
can be used to sample various different textures. ANGLE therefore swizzles the texture data itself. This consumes some
memory and incurs some overhead at texture upload. These costs can be avoided by not changing the TEXTURE_SWIZZLE_R,
TEXTURE_SWIZZLE_G, TEXTURE_SWIZZLE_B, and TEXTURE_SWIZZLE_A texture parameters from their defaults. If necessary, use
multiple shader variants to account for dif- ferent texture component orders. 




***** not use

- Avoid Uniform Buffer Binding Offsets
Uniform buffer objects (UBOs), newly added in OpenGL ES 3.0, are bound objects which store uniform data for the use of
GLSL shaders. UBOs offer benefits to developers, including the ability to share uniforms between programs and faster
switching between sets of uniforms. OpenGL ES 3.0 also allows UBOs, much like other buffer objects, to be bound at an
offset into the buffer, rather than just the buffer head. Direct3D, on the other hand, does not support referencing its
analogous structure, constant buffers, until Direct3D 11.1, with the addition of the VSSetConstantBuffers1 method [MSDN
14d]. Offsets are supported with a software workaround on all hardware of lower feature levels. Developers can avoid any
performance penalty associated with this workaround by binding UBOs at offset 0 only. 




***** need more understand!
- Avoid Three-Channel Uint8Array/Uint16Array Data in Vertex Buffers(can use four-channel with Uint32Array data)
Direct3D has limited support for three-channel vertex formats. Only 32-bit three- channel formats (both integer and
float) are supported natively [MSDN 14a]. Other three-channel formats are expanded by ANGLE to four-channel internally
when using a Direct3D backend. If the vertex buffer usage is dynamic, this con- version will be performed each time the
buffer is used in a draw. To avoid the expansion, use four-channel formats with 8- or 16-bit types. 


- Avoid Integer Cube Map Textures
Cube maps with unnormalized integer formats are not supported by Direct3D 11 [MSDN 14c]. The ANGLE team hasn’t
encountered any uses for it, which may be the reason it was left out of D3D11, but it is a feature of OpenGL ES 3.0 and
gets tested by the conformance tests. ANGLE therefore must emulate it in ANGLE’s ESSL to HLSL translator. The cube
texture is replaced by a six- layer 2D array texture, and the face from which to sample, and at what loca- tion, is
manually computed. Rather than unnormalized integer formats, we recommend using normalized integer formats for cube
maps. If integer values are expected, multiply the sampled value by the maximum integer value, and round to the nearest
integer. For example, for signed 16-bit integers: int i = int(round(32767 * f)); 



- Beware of Shadow Lookups in 2D Array Textures
Our final recommendation is a minor one, because the range of hardware affected is relatively small. Shadow comparison
lookups are a feature introduced in OpenGL ES 3.0. These texture lookups can perform prefilter comparison of depth data
contained in a texture against a provided reference value. ES 3.0 also intro- duces new texture types, including 2D
texture arrays. Where these two features intersect, a caveat emerges. Direct3D 11 does support shadow lookups for 2D
tex- ture arrays—but not at feature level 10_0 [MSDN 14e]. For this reason, ANGLE must either exclude feature level 10_0
hardware from ES 3.0 support or implement a workaround, with potential performance penalties. If the latter approach is
cho- sen, developers may encounter performance issues on Direct3D 10.0 hardware. If the former approach is chosen
instead, then OpenGL ES 3.0 would not be avail- able on this hardware at all. 






**** TODO firefox implement webgl(refer to <<WebGL Insights>>->chapter 2):

- Each drawElements call can only work with one index
type anyway. Keep separate index types in separate element array
buffers. 

Using the same element array buffer with multiple index types only
requires the implementation to maintain separate trees for each type;
there are three pos- sible types so there can be up to three trees to
maintain for a given element array buffer, which multiplies by three
the memory usage and speed overhead. Just don’t do it. There is no
good reason to: Each drawElements call can only work with one index
type anyway. Keep separate index types in separate element array
buffers. 


- So if you don’t need to update a frame, don’t it, don’t even call clear. 

The first conclusion of this discussion is that if you don’t need to
update a frame, avoid- ing re-rendering it will save not only the time
it takes to render it, but also a lot of inter- nal compositing work
and synchronization. So if you don’t need to update a frame, don’t
touch it, don’t even call clear. 

**** TODO refer to <<WebGL Insights>>->chapter 4:
This means that if we want to expose a property on an object, it’s
faster to make it a public field rather than abstract it behind get
and set methods 



**** TODO refer to <<WebGL Insights>>->chapter 8(mobile chapter):

An application should not have unnecessary “get” calls of any kind,
especially getError, or frequent calls requiring synchronization like
readPixels, flush, or finish.  


***** Reducing Bandwidth Usage

The more obvious ways to reduce bandwidth are reducing texture or
framebuffer reso- lution.  



optimize full-screen effects
Implementing full-screen effects in an efficient way or avoiding them
altogether can also enable huge bandwidth savings [McCaffrey 12;
Pranckevičius 11]. In particular, it is better to combine different
postprocessing filters into a single shader or add simple post-
processing effects directly into the shaders used to render geometry,
when possible. 



Using lots of small polygons also costs bandwidth on tiler
architectures, since they need to access the vertex data separately
for each tile [Merry 12]. Optimizing models to minimize the vertex and
triangle count helps on these GPUs. 


**** TODO refer to <<WebGL Insights>>->chapter 10(Turbulenz Engine):

cull lights:
For lights, we may go an extra step by projecting the bounding box
into the screen to calculate how many pixels it would actually light,
discarding the light or disabling its shadows’ maps depending on its
contribution to the scene. 


**** TODO refer to <<WebGL Insights>>->chapter 14:

When the user spins the model around its turntable using a touch
interface, a smooth frame rate is achieved by rendering to a
low-resolution framebuffer (left). When the user lifts her fingers, we
redraw the model in full resolution (right). 

Listing 14.7 Low-fidelity/high-fidelity modes for glass effect.
MyEngine.Buddha = function() { this.framebuffers = {lo: null, hi: null}; this.textures = {lo: null, hi: null};
};
MyEngine.Buddha.draw = function(gl, turntable) {
var texture, canvas = gl.canvas;
if (turntable.state = = turntable.states.Resting) {
//Use a full-resolution framebuffer:
texture = this.textures.hi; gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffers.hi); gl.viewport(0, 0, canvas.width, canvas.height);
} else {
//Use a half-resolution framebuffer:
texture = this.textures.lo; gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffers.lo); gl.viewport(0, 0, canvas.width/2, canvas.height/2);
}
    //...draw Buddha to offscreen surface...
    gl.viewport(0, 0, canvas.width, canvas.height);
    gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    gl.bindTexture(gl.TEXTURE_2D, texture);
    //...draw fullscreen triangle to canvas...
    gl.bindTexture(gl.TEXTURE_2D, null);
};
￼

** TODO optimize from <<游戏引擎架构>>
资源运行时管理：
通过记录引用数来释放资源（p265)

增量时间：
设置上限（p292)

调试：
//开发绘制直线、坐标轴等调试绘图api

//研究data driven engine(p656)

//改进GameObject->update:
use batch update(p679)


//sky box:
close depth write(p441)



** TODO reference
http://www.cppblog.com/liangairan/archive/2013/03/23/198749.html

** TODO add debug Panel(second version)
use ui component to draw

refactor:
add DebugDrawer class


add more info like bjs




** TODO improve transform
learn GPU Pro 5->managing transforms in hierarchy














* Record
** jest->ts-jest
*** fix: fix ts-jest->the "import" in "import List" is "unExpected token" bug!(if .ts file import Collection from wonder-commonlib)
description
if .ts file->import { Collection } from "wonder-commonlib/dist/commonjs/Collection";

then it will error


reason
jest import wonder-commonlib/dist/commonjs/Collection.ts file instead of .js file!!!

because jest judge the extname of file based on package.json->"jest"->"moduleFileExtensions"!

solution
change package.json->"jest"->"moduleFileExtensions", put "js" firstly:
    "moduleFileExtensions": [
      "js",
      "ts",
      "tsx"
    ]




* TODO unsolved problem
** TODO Wonder-Sample-ES2015 project: why "generateDTS" gulp task will generate dist/es2015/src and node_module files!!!???

** TODO how to ts compile worker file code?

** TODO codecov
should coverage both wd.js and wd.renderWorker.js!


* TODO need improve



* TODO more

